# eco-base v1.0 - Ollama Engine StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ollama
  namespace: eco-base
  labels:
    app.kubernetes.io/name: ollama
    app.kubernetes.io/component: inference-engine
    app.kubernetes.io/part-of: eco-base
spec:
  serviceName: ollama-svc
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ollama
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ollama
        app.kubernetes.io/component: inference-engine
    spec:
      serviceAccountName: eco-sa
      terminationGracePeriodSeconds: 60
      containers:
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - name: http
              containerPort: 11434
          resources:
            requests:
              cpu: "2"
              memory: "8Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "4"
              memory: "16Gi"
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama
          readinessProbe:
            httpGet:
              path: /
              port: 11434
            initialDelaySeconds: 30
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /
              port: 11434
            initialDelaySeconds: 60
            periodSeconds: 30
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
  volumeClaimTemplates:
    - metadata:
        name: ollama-data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 100Gi
---
apiVersion: v1
kind: Service
metadata:
  name: ollama-svc
  namespace: eco-base
  labels:
    app.kubernetes.io/name: ollama
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 11434
      targetPort: 11434
  selector:
    app.kubernetes.io/name: ollama
---
# YAML Toolkit v8 â€” Governance Block (auto-generated, manual editing prohibited)
document_metadata:
  unique_id: "eco-ol-0001-0001-000000000001"
  uri: "eco-base://k8s/eco-base/statefulset/ollama"
  urn: "urn:eco-base:k8s:eco-base:statefulset:ollama:eco-ol-0001-0001-000000000001"
  target_system: gke-production
  cross_layer_binding: [api-gateway, ai-service]
  schema_version: v8
  generated_by: yaml-toolkit-v8
  created_at: "2025-02-18T00:00:00.000Z"
governance_info:
  owner: platform-team
  approval_chain: [platform-team, ml-team]
  compliance_tags: [zero-trust, soc2, internal, gpu-workload, inference]
  lifecycle_policy: active
registry_binding:
  service_endpoint: "http://ollama-svc.eco-base.svc.cluster.local:11434"
  discovery_protocol: consul
  health_check_path: "/"
  registry_ttl: 30
vector_alignment_map:
  alignment_model: quantum-bert-xxl-v1
  coherence_vector_dim: 1024
  function_keyword: [ollama, inference, gpu, embedding, local-models]
  contextual_binding: "ollama -> [api-gateway, ai-service]"
