# eco-base v1.0 - SGLang Inference Engine StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sglang
  namespace: eco-base
  labels:
    app.kubernetes.io/name: sglang
    app.kubernetes.io/component: inference-engine
    app.kubernetes.io/part-of: eco-base
spec:
  serviceName: sglang-svc
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: sglang
  template:
    metadata:
      labels:
        app.kubernetes.io/name: sglang
        app.kubernetes.io/component: inference-engine
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8003"
    spec:
      serviceAccountName: eco-sa
      terminationGracePeriodSeconds: 120
      containers:
        - name: sglang
          image: lmsysorg/sglang:v0.3.6-cu124
          ports:
            - name: http
              containerPort: 8003
          args:
            - "python3"
            - "-m"
            - "sglang.launch_server"
            - "--host=0.0.0.0"
            - "--port=8003"
            - "--model-path=meta-llama/Llama-3.1-8B-Instruct"
            - "--mem-fraction-static=0.88"
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: eco-secrets
                  key: HF_TOKEN
          resources:
            requests:
              cpu: "4"
              memory: "16Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "8"
              memory: "32Gi"
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: model-cache
              mountPath: /root/.cache/huggingface
            - name: shm
              mountPath: /dev/shm
          readinessProbe:
            httpGet:
              path: /health
              port: 8003
            initialDelaySeconds: 120
            periodSeconds: 15
            timeoutSeconds: 10
            failureThreshold: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8003
            initialDelaySeconds: 180
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 5
      volumes:
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
  volumeClaimTemplates:
    - metadata:
        name: model-cache
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 100Gi
---
apiVersion: v1
kind: Service
metadata:
  name: sglang-svc
  namespace: eco-base
  labels:
    app.kubernetes.io/name: sglang
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8003
      targetPort: 8003
  selector:
    app.kubernetes.io/name: sglang
---
# YAML Toolkit v8 â€” Governance Block (auto-generated, manual editing prohibited)
document_metadata:
  unique_id: "eco-sg-0001-0001-000000000001"
  uri: "eco-base://k8s/eco-base/statefulset/sglang"
  urn: "urn:eco-base:k8s:eco-base:statefulset:sglang:eco-sg-0001-0001-000000000001"
  target_system: gke-production
  cross_layer_binding: [api-gateway, ai-service]
  schema_version: v8
  generated_by: yaml-toolkit-v8
  created_at: "2025-02-18T00:00:00.000Z"
governance_info:
  owner: platform-team
  approval_chain: [platform-team, ml-team]
  compliance_tags: [zero-trust, soc2, internal, gpu-workload, inference]
  lifecycle_policy: active
registry_binding:
  service_endpoint: "http://sglang-svc.eco-base.svc.cluster.local:8003"
  discovery_protocol: consul
  health_check_path: "/health"
  registry_ttl: 30
vector_alignment_map:
  alignment_model: quantum-bert-xxl-v1
  coherence_vector_dim: 1024
  function_keyword: [sglang, inference, gpu, structured-output, radix-attention]
  contextual_binding: "sglang -> [api-gateway, ai-service]"
