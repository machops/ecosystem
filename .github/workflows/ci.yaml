name: IndestructibleEco CI/CD

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

permissions:
  contents: write
  actions: write

env:
  REGISTRY: ghcr.io/indestructibleorg
  PYTHON_VERSION: "3.11"

jobs:
  # ════════════════════════════════════════════════════════════════
  # Gate 1: Centralized Validation Engine
  # ════════════════════════════════════════════════════════════════
  validate:
    runs-on: ubuntu-latest
    outputs:
      error_count: ${{ steps.validator.outputs.error_count }}
    steps:
    - name: Checkout
      run: |
        git clone --depth 1 https://github.com/${{ github.repository }}.git .
        git checkout ${{ github.sha }}

    - name: Run CI Validator Engine
      id: validator
      run: |
        python3 tools/ci-validator/validate.py --report=/tmp/validation-report.json
        echo "error_count=0" >> "$GITHUB_OUTPUT"

    - name: Upload validation report
      if: always()
      run: |
        if [ -f /tmp/validation-report.json ]; then
          echo "=== Validation Report ==="
          cat /tmp/validation-report.json | python3 -m json.tool
        fi

  # ════════════════════════════════════════════════════════════════
  # Gate 2: Python Lint & Compile
  # ════════════════════════════════════════════════════════════════
  lint:
    runs-on: ubuntu-latest
    needs: validate
    steps:
    - name: Checkout
      run: |
        git clone --depth 1 https://github.com/${{ github.repository }}.git .
        git checkout ${{ github.sha }}

    - name: Python compile check
      run: |
        python3 -m py_compile backend/ai/src/app.py
        python3 -m py_compile backend/ai/src/config.py
        python3 -m py_compile backend/ai/src/routes.py
        python3 -m py_compile backend/ai/src/governance.py
        python3 -m py_compile backend/shared/models/__init__.py
        python3 -m py_compile backend/shared/utils/__init__.py
        python3 -m py_compile tools/ci-validator/validate.py
        python3 -m py_compile tools/ci-validator/auto-fix.py
        python3 -m py_compile tools/skill-creator/scripts/init_skill.py
        python3 -m py_compile tools/skill-creator/scripts/quick_validate.py
        python3 -m py_compile src/app.py
        python3 -m py_compile src/schemas/auth.py
        python3 -m py_compile src/schemas/inference.py
        python3 -m py_compile src/schemas/models.py
        python3 -m py_compile src/middleware/auth.py
        python3 -m py_compile src/core/queue.py
        python3 -m py_compile src/core/registry.py
        python3 -m py_compile backend/ai/src/services/__init__.py
        python3 -m py_compile backend/ai/src/services/circuit_breaker.py
        python3 -m py_compile backend/ai/src/services/connection_pool.py
        python3 -m py_compile backend/ai/src/services/engine_manager.py
        python3 -m py_compile backend/ai/src/services/worker.py
        python3 -m py_compile backend/ai/src/services/embedding.py
        python3 -m py_compile backend/ai/src/services/grpc_server.py
        python3 -m py_compile backend/ai/src/services/health_monitor.py
        echo "Python compile check passed"

    - name: JS syntax check
      run: |
        node --check tools/yaml-toolkit/bin/cli.js
        node --check tools/yaml-toolkit/bin/validate-qyaml.js
        node --check tools/skill-creator/scripts/validate.js
        echo "JS syntax check passed"

    - name: YAML governance lint (strict)
      run: |
        FAIL=0
        COUNT=0
        for f in $(find backend/k8s k8s -name "*.qyaml" -type f 2>/dev/null); do
          COUNT=$((COUNT + 1))
          echo "Checking $f"
          for block in document_metadata governance_info registry_binding vector_alignment_map; do
            if ! grep -q "${block}:" "$f"; then
              echo "  FAIL: Missing $block in $f"
              FAIL=1
            fi
          done
          for field in unique_id uri urn target_system schema_version generated_by; do
            if ! grep -q "${field}:" "$f"; then
              echo "  FAIL: Missing $field in $f"
              FAIL=1
            fi
          done
          # GKE compatibility — only flag actual %YAML directives at line start
          if grep -qP '^\s*%YAML' "$f"; then
            echo "  FAIL: GKE-incompatible %YAML directive in $f"
            FAIL=1
          fi
          echo "  PASS: $f"
        done
        echo "Checked $COUNT .qyaml files"
        if [ "$FAIL" -eq 1 ]; then exit 1; fi
        echo "All .qyaml files passed governance validation"

    - name: Skill manifest validation
      run: |
        node tools/skill-creator/scripts/validate.js tools/skill-creator/skills
        echo "Skill manifest validation passed"

  # ════════════════════════════════════════════════════════════════
  # Gate 3: Unit & Integration Tests
  # ════════════════════════════════════════════════════════════════
  test:
    runs-on: ubuntu-latest
    needs: lint
    steps:
    - name: Checkout
      run: |
        git clone --depth 1 https://github.com/${{ github.repository }}.git .
        git checkout ${{ github.sha }}

    - name: Core module tests (schemas, auth, queue, registry, API)
      run: |
        pip install pytest pytest-asyncio pydantic fastapi httpx numpy pyyaml -q 2>/dev/null
        PYTHONPATH=. python3 -m pytest tests/ -v --tb=short
        echo "Core + E2E tests passed"

    - name: Config tests
      run: |
        cat > /tmp/test_config.py << 'PYEOF'
        import sys
        sys.path.insert(0, '.')
        from src.config import Settings
        s = Settings()
        assert s.http_port == 8001
        assert s.grpc_port == 8000
        assert s.vector_dim == 1024
        assert s.alignment_model == 'quantum-bert-xxl-v1'
        print('Config tests passed')
        PYEOF
        cd backend/ai && python3 /tmp/test_config.py

    - name: Governance engine tests
      run: |
        cat > /tmp/test_governance.py << 'PYEOF'
        import sys
        sys.path.insert(0, '.')
        from src.governance import GovernanceEngine
        g = GovernanceEngine()
        engine = g.resolve_engine('vllm-default')
        assert engine == 'vllm_adapter', f'Expected vllm_adapter, got {engine}'
        engine = g.resolve_engine('ollama-chat')
        assert engine == 'ollama_adapter', f'Expected ollama_adapter, got {engine}'
        stamp = g.stamp_governance('test-svc', 'indestructibleeco', 'Deployment')
        assert stamp['document_metadata']['schema_version'] == 'v1'
        assert stamp['document_metadata']['generated_by'] == 'yaml-toolkit-v1'
        assert 'indestructibleeco://' in stamp['document_metadata']['uri']
        assert 'urn:indestructibleeco:' in stamp['document_metadata']['urn']
        assert stamp['vector_alignment_map']['alignment_model'] == 'quantum-bert-xxl-v1'
        log = g.get_audit_log()
        assert len(log) >= 2
        print('Governance engine tests passed')
        PYEOF
        cd backend/ai && python3 /tmp/test_governance.py

    - name: Shared utils tests
      run: |
        cat > /tmp/test_utils.py << 'PYEOF'
        import sys
        sys.path.insert(0, '.')
        from backend.shared.utils import new_uuid, new_uuid_str, build_uri, build_urn, build_k8s_uri, build_k8s_urn, governance_stamp, build_qyaml_metadata
        uid = new_uuid()
        assert uid.version == 1
        uri = build_uri('k8s', 'deployment', 'test')
        assert uri == 'indestructibleeco://k8s/deployment/test'
        urn = build_urn('k8s', 'deployment', 'test', uid)
        assert 'urn:indestructibleeco:' in urn
        stamp = governance_stamp()
        assert stamp['schema_version'] == 'v1'
        meta = build_qyaml_metadata('api', 'indestructibleeco', 'Deployment', 'gke-production')
        assert 'document_metadata' in meta
        assert 'governance_info' in meta
        assert 'registry_binding' in meta
        assert 'vector_alignment_map' in meta
        print('Shared utils tests passed')
        PYEOF
        python3 /tmp/test_utils.py

    - name: YAML Toolkit tests
      run: |
        mkdir -p /tmp/toolkit-test
        echo '{"name":"test-svc","image":"ghcr.io/test:v1","replicas":2,"ports":[3000],"depends_on":["redis"]}' > /tmp/toolkit-test/module.json
        node tools/yaml-toolkit/bin/cli.js gen --input=/tmp/toolkit-test/module.json --output=/tmp/toolkit-test
        node tools/yaml-toolkit/bin/cli.js validate /tmp/toolkit-test/test-svc.qyaml
        echo "YAML Toolkit tests passed"

    - name: Skill creator tests
      run: |
        pip install pytest jsonschema -q 2>/dev/null
        python3 -m pytest tools/skill-creator/skills/ -v --tb=short
        echo "Skill creator tests passed"

  # ════════════════════════════════════════════════════════════════
  # Gate 4: Docker Build
  # ════════════════════════════════════════════════════════════════
  build:
    runs-on: ubuntu-latest
    needs: test
    steps:
    - name: Checkout
      run: |
        git clone --depth 1 https://github.com/${{ github.repository }}.git .
        git checkout ${{ github.sha }}

    - name: Build AI Docker image
      run: |
        docker build -t ${{ env.REGISTRY }}/ai:${{ github.sha }} -f backend/ai/Dockerfile backend/ai/
        echo "AI Docker image built successfully"

    - name: Verify repository structure
      run: |
        FAIL=0
        for dir in \
          backend/api backend/ai backend/shared/proto backend/shared/models \
          backend/k8s/namespaces backend/k8s/deployments backend/k8s/services \
          backend/k8s/ingress backend/k8s/configmaps backend/k8s/secrets backend/k8s/security \
          backend/cloudflare/workers backend/supabase/migrations \
          packages/shared-types packages/api-client packages/ui-kit \
          platforms/web platforms/desktop platforms/im-integration platforms/platform-template \
          ecosystem/monitoring ecosystem/tracing ecosystem/service-discovery \
          ecosystem/logging ecosystem/gateway \
          tools/yaml-toolkit tools/skill-creator tools/ci-validator \
          k8s/base k8s/ingress k8s/monitoring k8s/argocd \
          src src/schemas src/middleware src/core docs \
          helm/templates \
          platforms/im-integration/whatsapp/src platforms/im-integration/line/src \
          platforms/im-integration/messenger/src platforms/desktop/resources; do
          if [ -d "$dir" ]; then
            echo "  PASS: $dir"
          else
            echo "  FAIL: $dir missing"
            FAIL=1
          fi
        done
        for file in \
          backend/k8s/kustomization.yaml \
          backend/api/Dockerfile \
          backend/api/openapi.yaml \
          backend/cloudflare/wrangler.toml \
          backend/supabase/migrations/001_initial_schema.sql \
          tools/ci-validator/validate.py \
          tools/ci-validator/auto-fix.py \
          tools/skill-creator/SKILL.md \
          k8s/argocd/argo-app.yaml \
          scripts/argocd-install.sh \
          Makefile \
          tools/yaml-toolkit/bin/validate-qyaml.js \
          tsconfig.base.json \
          tsconfig.json \
          .eslintrc.json \
          .prettierrc \
          helm/templates/deployment.yaml \
          helm/templates/service.yaml \
          helm/templates/hpa.yaml \
          helm/templates/pdb.yaml \
          helm/templates/configmap.yaml \
          helm/templates/secrets.yaml \
          helm/templates/serviceaccount.yaml \
          helm/templates/networkpolicy.yaml \
          helm/templates/servicemonitor.yaml \
          platforms/desktop/resources/icon.png \
          tests/e2e/test_full_flow.py \
          tests/e2e/test_service_lifecycle.py \
          tests/unit/test_governance_engine.py \
          tests/unit/test_folding_engines.py \
          tests/unit/test_index_config.py \
          tests/unit/test_adapter_resilience.py \
          tests/unit/test_gateway_proxy.py \
          tests/unit/test_shared_db.py \
          tests/unit/test_proto_stubs.py \
          tests/unit/test_api_types.py \
          tests/unit/test_yaml_studio.py \
          tests/unit/test_ui_kit.py \
          tests/unit/test_api_client.py \
          tests/unit/test_grafana_dashboard.py \
          tests/unit/test_alert_rules.py \
          tests/unit/test_docker_compose.py \
          tests/unit/test_argocd_appset.py \
          tests/unit/test_security.py \
          tests/unit/test_docs.py \
          tests/unit/test_readme.py \
          backend/ai/src/services/engine_manager.py \
          backend/ai/src/services/circuit_breaker.py \
          CHANGELOG.md \
          tests/unit/test_release.py \
          .github/workflows/release.yml \
          .github/workflows/publish-npm.yml \
          .github/workflows/publish-docker.yml \
          .github/workflows/publish-pypi.yml; do
          if [ -f "$file" ]; then
            echo "  PASS: $file"
          else
            echo "  FAIL: $file missing"
            FAIL=1
          fi
        done
        if [ "$FAIL" -eq 1 ]; then exit 1; fi
        echo "All structure checks passed"

  # ══════════════════════════════════════════════════════════════════
  # Gate 5: Auto-Fix Engine (runs on failure, attempts automated repair)
  # ══════════════════════════════════════════════════════════════════
  auto-fix:
    runs-on: ubuntu-latest
    needs: [validate, lint, test, build]
    if: failure() && github.ref == 'refs/heads/main'
    steps:
    - name: Checkout
      run: |
        git clone --depth 1 https://github.com/${{ github.repository }}.git .
        git checkout ${{ github.sha }}

    - name: Run Auto-Fix Engine (diagnostic mode)
      run: |
        python3 tools/ci-validator/auto-fix.py --dry-run --report=/tmp/auto-fix-report.json
        echo "=== Auto-Fix Diagnostic Report ==="
        if [ -f /tmp/auto-fix-report.json ]; then
          cat /tmp/auto-fix-report.json | python3 -m json.tool
        fi
        echo ""
        echo "NOTE: Auto-fix runs in dry-run mode in CI."
        echo "To apply fixes locally, run:"
        echo "  python3 tools/ci-validator/auto-fix.py"