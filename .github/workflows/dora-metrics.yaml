name: DORA Metrics — Deployment Frequency, Lead Time, MTTR, CFR
on:
  workflow_run:
    workflows: ["eco-base CI/CD", "Auto-Sync Deploy — GitHub → GCP/GKE + Supabase + Cloudflare"]
    types: [completed]
  schedule:
    - cron: '0 0 * * 1'
  workflow_dispatch:

permissions:
  contents: read
  issues: write
  pull-requests: read
  id-token: write

concurrency:
  group: dora-metrics-${{ github.ref }}
  cancel-in-progress: false

jobs:
  collect-dora-metrics:
    name: Collect and Report DORA Metrics
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683  # v4.2.2
        with:
          fetch-depth: 0

      - name: Collect DORA metrics
        id: metrics
        env:
          GITHUB_TOKEN: ${{ github.token }}
          CI_CONCLUSION: ${{ github.event.workflow_run.conclusion }}
          CI_WORKFLOW: ${{ github.event.workflow_run.name }}
        run: |
          python3 << 'PYEOF'
          import json, os, urllib.request
          from datetime import datetime, timezone, timedelta

          token = os.environ.get("GITHUB_TOKEN", "")
          repo = os.environ.get("GITHUB_REPOSITORY", "")
          now = datetime.now(timezone.utc)
          window_days = 30
          since = (now - timedelta(days=window_days)).isoformat()

          def gh_api(path, params=""):
              url = f"https://api.github.com/repos/{repo}{path}{params}"
              headers = {"Authorization": f"token {token}", "Accept": "application/vnd.github.v3+json"}
              req = urllib.request.Request(url, headers=headers)
              try:
                  with urllib.request.urlopen(req) as r:
                      return json.loads(r.read())
              except Exception as e:
                  print(f"API error {path}: {e}")
                  return []

          # 1. Deployment Frequency — count successful deployments in last 30 days
          deployments = gh_api("/deployments", f"?per_page=100&since={since}")
          successful_deploys = []
          if isinstance(deployments, list):
              for d in deployments:
                  statuses = gh_api(f"/deployments/{d.get('id', 0)}/statuses")
                  if isinstance(statuses, list) and statuses and statuses[0].get("state") == "success":
                      successful_deploys.append(d)

          deploy_count = len(successful_deploys)
          deploy_freq_per_day = deploy_count / window_days if window_days > 0 else 0
          if deploy_freq_per_day >= 1:
              deploy_rating = "Elite"
          elif deploy_freq_per_day >= 1/7:
              deploy_rating = "High"
          elif deploy_freq_per_day >= 1/30:
              deploy_rating = "Medium"
          else:
              deploy_rating = "Low"

          # 2. Lead Time for Changes — time from first commit to deploy
          merged_prs = gh_api("/pulls", f"?state=closed&sort=updated&direction=desc&per_page=30")
          lead_times = []
          if isinstance(merged_prs, list):
              for pr in merged_prs[:20]:
                  if pr.get("merged_at"):
                      created = datetime.fromisoformat(pr["created_at"].replace("Z", "+00:00"))
                      merged = datetime.fromisoformat(pr["merged_at"].replace("Z", "+00:00"))
                      lead_times.append((merged - created).total_seconds() / 3600)

          avg_lead_time_h = sum(lead_times) / len(lead_times) if lead_times else 0
          if avg_lead_time_h < 1:
              lead_time_rating = "Elite"
          elif avg_lead_time_h < 24:
              lead_time_rating = "High"
          elif avg_lead_time_h < 24 * 7:
              lead_time_rating = "Medium"
          else:
              lead_time_rating = "Low"

          # 3. Change Failure Rate — failed deployments / total deployments
          all_runs = gh_api("/actions/runs", f"?per_page=100&created=>={since}&branch=main")
          total_runs = 0
          failed_runs = 0
          if isinstance(all_runs, dict):
              workflow_runs = all_runs.get("workflow_runs", [])
              total_runs = len(workflow_runs)
              failed_runs = sum(1 for r in workflow_runs if r.get("conclusion") == "failure")

          cfr = (failed_runs / total_runs * 100) if total_runs > 0 else 0
          if cfr <= 5:
              cfr_rating = "Elite"
          elif cfr <= 10:
              cfr_rating = "High"
          elif cfr <= 15:
              cfr_rating = "Medium"
          else:
              cfr_rating = "Low"

          # 4. MTTR — mean time to restore (approximated by time to close failure issues)
          issues = gh_api("/issues", f"?state=closed&labels=incident,outage&since={since}&per_page=50")
          mttr_hours = []
          if isinstance(issues, list):
              for issue in issues:
                  if issue.get("closed_at") and issue.get("created_at"):
                      created = datetime.fromisoformat(issue["created_at"].replace("Z", "+00:00"))
                      closed = datetime.fromisoformat(issue["closed_at"].replace("Z", "+00:00"))
                      mttr_hours.append((closed - created).total_seconds() / 3600)

          avg_mttr_h = sum(mttr_hours) / len(mttr_hours) if mttr_hours else 0
          if avg_mttr_h < 1:
              mttr_rating = "Elite"
          elif avg_mttr_h < 24:
              mttr_rating = "High"
          elif avg_mttr_h < 24 * 7:
              mttr_rating = "Medium"
          else:
              mttr_rating = "Low" if mttr_hours else "N/A (no incidents)"

          # Output metrics
          metrics = {
              "timestamp": now.isoformat(),
              "window_days": window_days,
              "deployment_frequency": {
                  "count": deploy_count,
                  "per_day": round(deploy_freq_per_day, 3),
                  "rating": deploy_rating,
              },
              "lead_time_for_changes": {
                  "avg_hours": round(avg_lead_time_h, 1),
                  "sample_size": len(lead_times),
                  "rating": lead_time_rating,
              },
              "change_failure_rate": {
                  "total_runs": total_runs,
                  "failed_runs": failed_runs,
                  "percentage": round(cfr, 1),
                  "rating": cfr_rating,
              },
              "mean_time_to_restore": {
                  "avg_hours": round(avg_mttr_h, 1),
                  "sample_size": len(mttr_hours),
                  "rating": mttr_rating,
              },
          }

          print(json.dumps(metrics, indent=2))

          # Write to GITHUB_OUTPUT
          with open(os.environ.get("GITHUB_OUTPUT", "/dev/null"), "a") as f:
              f.write(f"deploy_rating={deploy_rating}\n")
              f.write(f"lead_time_rating={lead_time_rating}\n")
              f.write(f"cfr_rating={cfr_rating}\n")
              f.write(f"cfr_pct={round(cfr, 1)}\n")
              f.write(f"mttr_rating={mttr_rating}\n")
              f.write(f"metrics_json={json.dumps(metrics)}\n")

          # Alert if CFR > 5% (SLO breach)
          if cfr > 5:
              print(f"\nSLO BREACH: Change Failure Rate {cfr:.1f}% exceeds 5% threshold!")
              with open(os.environ.get("GITHUB_OUTPUT", "/dev/null"), "a") as f:
                  f.write("slo_breach=true\n")
          else:
              with open(os.environ.get("GITHUB_OUTPUT", "/dev/null"), "a") as f:
                  f.write("slo_breach=false\n")
          PYEOF

      - name: Create SLO breach issue if CFR > 5%
        if: steps.metrics.outputs.slo_breach == 'true'
        env:
          GITHUB_TOKEN: ${{ github.token }}
          CFR_PCT: ${{ steps.metrics.outputs.cfr_pct }}
        run: |
          python3 -c '
          import json, os, urllib.request
          token = os.environ["GITHUB_TOKEN"]
          repo = os.environ["GITHUB_REPOSITORY"]
          cfr = os.environ["CFR_PCT"]

          # Check for existing open SLO breach issue
          url = f"https://api.github.com/repos/{repo}/issues?labels=slo-breach,dora&state=open"
          req = urllib.request.Request(url, headers={"Authorization": f"token {token}", "Accept": "application/vnd.github.v3+json"})
          with urllib.request.urlopen(req) as r:
              existing = json.loads(r.read())

          if existing:
              _n = existing[0]["number"]
              print(f"SLO breach issue already open: #{_n}")
          else:
              body = f"""## SLO Breach: Change Failure Rate Exceeded

          **Threshold:** 5%
          **Current CFR:** {cfr}%

          The Change Failure Rate has exceeded the SLO threshold. This means more than 5% of deployments to main are failing.

          ### Recommended Actions
          1. Review recent failed CI/CD runs
          2. Check if recent merges introduced regressions
          3. Consider pausing auto-merge until CFR returns below 5%

          ### DORA Reference
          - Elite: ≤5% CFR
          - High: ≤10% CFR
          - Medium: ≤15% CFR
          - Low: >15% CFR

          cc: @indestructiblemachinen
          """
              data = json.dumps({"title": f"SLO Breach: CFR {cfr}% exceeds 5% threshold", "body": body, "labels": ["slo-breach", "dora", "incident"]}).encode()
              req2 = urllib.request.Request(f"https://api.github.com/repos/{repo}/issues", data=data, method="POST",
                  headers={"Authorization": f"token {token}", "Accept": "application/vnd.github.v3+json", "Content-Type": "application/json"})
              with urllib.request.urlopen(req2) as r:
                  issue = json.loads(r.read())
              _in = issue["number"]
              print(f"Created SLO breach issue: #{_in}")
          '

      - name: Write DORA audit log
        if: always()
        env:
          METRICS_JSON: ${{ steps.metrics.outputs.metrics_json }}
          DEPLOY_RATING: ${{ steps.metrics.outputs.deploy_rating }}
          LEAD_TIME_RATING: ${{ steps.metrics.outputs.lead_time_rating }}
          CFR_RATING: ${{ steps.metrics.outputs.cfr_rating }}
          MTTR_RATING: ${{ steps.metrics.outputs.mttr_rating }}
        run: |
          python3 -c '
          import json, os
          from datetime import datetime, timezone
          entry = {
              "timestamp": datetime.now(timezone.utc).isoformat(),
              "type": "dora-metrics",
              "run_id": os.environ.get("GITHUB_RUN_ID", ""),
              "ratings": {
                  "deployment_frequency": os.environ.get("DEPLOY_RATING", ""),
                  "lead_time": os.environ.get("LEAD_TIME_RATING", ""),
                  "change_failure_rate": os.environ.get("CFR_RATING", ""),
                  "mttr": os.environ.get("MTTR_RATING", ""),
              },
              "compliance_tags": ["SOC2", "ISO27001", "DORA", "audit-trail"],
          }
          print(json.dumps(entry, indent=2))
          '
