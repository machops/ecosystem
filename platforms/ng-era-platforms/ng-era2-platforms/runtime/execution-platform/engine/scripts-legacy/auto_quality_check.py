#
# @ECO-governed
# @ECO-layer: gl-platform.gl-platform.governance
# @ECO-semantic: auto-quality-check
# @ECO-audit-trail: ../../engine/gl-platform.gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
#!/usr/bin/env python3
"""
è‡ªå‹•åŒ–ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥å·¥å…·
Automated Code Quality Check Tool
æ­¤è…³æœ¬è‡ªå‹•åŸ·è¡Œ PR-1-REVIEW-REPORT.md ä¸­è­˜åˆ¥çš„æ‰€æœ‰æª¢æŸ¥é …ç›®
This script automatically performs all checks identified in PR-1-REVIEW-REPORT.md
"""
# MNGA-002: Import organization needs review
import subprocess
import json
from pathlib import Path
from typing import Dict, Any
import argparse
from datetime import datetime
import ast  # Added for ast.literal_eval()

class QualityChecker:
    """è‡ªå‹•åŒ–å“è³ªæª¢æŸ¥å™¨"""
    def __init__(self, repo_root: Path):
        self.repo_root = repo_root
        self.results: Dict[str, Any] = {}

    def _sanitize_results_for_report(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """
        å®‰å…¨åœ°éæ¿¾çµæœä¸­çš„æ•æ„Ÿè³‡æ–™ï¼Œé¿å…åœ¨å ±å‘Šä¸­ä»¥æ˜æ–‡å„²å­˜ã€‚
        åƒ…ä¿ç•™å¿…è¦çš„æ‘˜è¦è³‡è¨Šï¼ˆä¾‹å¦‚è¨ˆæ•¸ï¼‰ï¼Œä¸¦å°å¯èƒ½çš„æ•æ„Ÿæ¬„ä½é€²è¡Œé®ç½©ã€‚
        """
        # å®šç¾©å¯èƒ½åŒ…å«æ•æ„Ÿè³‡è¨Šçš„æ¬„ä½åç¨±
        sensitive_keys = {
            "secrets",
            "tokens",
            "passwords",
            "keys",
            "credentials",
            "secret_values",
        }
        sanitized: Dict[str, Any] = {}
        for check_name, result in results.items():
            if not isinstance(result, dict):
                # éé æœŸæ ¼å¼ï¼Œç›´æ¥è¤‡è£½ï¼ˆé€šå¸¸ä¸æœƒåŒ…å«æ•æ„Ÿè³‡è¨Šï¼‰
                sanitized[check_name] = result
                continue
            sanitized_result: Dict[str, Any] = {}
            for key, value in result.items():
                if key in sensitive_keys:
                    # çµ±ä¸€é®ç½©æ½›åœ¨æ•æ„Ÿè³‡æ–™
                    sanitized_result[key] = "[REDACTED FOR SECURITY]"
                elif isinstance(value, list):
                    # åƒ…ä¿ç•™æ¸…å–®é•·åº¦ï¼Œé¿å…æ„å¤–å°‡æ•æ„Ÿå­—ä¸²å¯«å…¥å ±å‘Š
                    sanitized_result[key] = {
                        "count": len(value),
                        "note": "List content omitted for security"
                    }
                else:
                    sanitized_result[key] = value
            sanitized[check_name] = sanitized_result
        return sanitized
    def run_all_checks(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ‰€æœ‰æª¢æŸ¥"""
        print("ğŸš€ é–‹å§‹è‡ªå‹•åŒ–å“è³ªæª¢æŸ¥...")
        self.check_security()
        self.check_python_quality()
        self.check_typescript_quality()
        self.check_code_duplication()
        self.check_docstring_coverage()
        self.check_non_ascii_filenames()
        self.check_console_logs()
        self.check_eval_usage()
        self.generate_report()
        return self.results
    def check_security(self):
        """P0: å®‰å…¨æ€§æª¢æŸ¥"""
        print("\nğŸ”’ åŸ·è¡Œå®‰å…¨æ€§æª¢æŸ¥...")
        try:
            # ä½¿ç”¨ detect-secrets
            result = subprocess.run(
                ["detect-secrets", "scan"],
                capture_output=True,
                text=True,
                cwd=self.repo_root
            )
            secrets_found = "no secrets" not in result.stdout.lower()
            self.results["security"] = {
                "status": "âš ï¸ WARNING" if secrets_found else "âœ… PASS",
                "secrets_detected": secrets_found,
                "details": "è«‹å¯©æŸ¥åŒ…å«æ•æ„Ÿé—œéµå­—çš„æª”æ¡ˆ" if secrets_found else "æœªæª¢æ¸¬åˆ°æ˜é¡¯çš„ç§˜å¯†"
            }
        except FileNotFoundError:
            self.results["security"] = {
                "status": "âš ï¸ SKIP",
                "details": "detect-secrets æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install detect-secrets"
            }
    def check_python_quality(self):
        """P0: Python ç¨‹å¼ç¢¼å“è³ª"""
        print("\nğŸ æª¢æŸ¥ Python ç¨‹å¼ç¢¼å“è³ª...")
        # çµ±è¨ˆå‹åˆ¥æç¤º
        py_files = list(self.repo_root.glob("**/*.py"))
        total_files = len(py_files)
        files_with_type_hints = 0
        for py_file in py_files:
            try:
                content = py_file.read_text()
                # ä½¿ç”¨æ›´ç²¾ç¢ºçš„æ¨¡å¼æª¢æ¸¬å‡½å¼å›å‚³å‹åˆ¥æç¤º
                if "def " in content and "->" in content:
                    files_with_type_hints += 1
            except (UnicodeDecodeError, OSError, PermissionError):
                continue
        type_hint_coverage = (files_with_type_hints / total_files * 100) if total_files > 0 else 0
        self.results["python_quality"] = {
            "total_files": total_files,
            "files_with_type_hints": files_with_type_hints,
            "type_hint_coverage": f"{type_hint_coverage:.1f}%",
            "status": "âœ… PASS" if type_hint_coverage >= 90 else "âš ï¸ WARNING",
            "target": "90%"
        }
    def check_typescript_quality(self):
        """P1: TypeScript/JavaScript å“è³ª"""
        print("\nğŸ“˜ æª¢æŸ¥ TypeScript ç¨‹å¼ç¢¼å“è³ª...")
        ts_files = list(self.repo_root.glob("**/*.ts")) + list(self.repo_root.glob("**/*.tsx"))
        js_files = list(self.repo_root.glob("**/*.js")) + list(self.repo_root.glob("**/*.jsx"))
        self.results["typescript_quality"] = {
            "total_ts_files": len(ts_files),
            "total_js_files": len(js_files),
            "status": "âœ… PASS"
        }
    def check_code_duplication(self):
        """P0: ç¨‹å¼ç¢¼é‡è¤‡æª¢æŸ¥"""
        print("\nğŸ”„ æª¢æŸ¥ç¨‹å¼ç¢¼é‡è¤‡...")
        # æª¢æŸ¥å·²çŸ¥çš„é‡è¤‡æ¨¡çµ„
        duplicate_patterns = [
            "dependency-manager",
            "drone_system"
        ]
        duplicates_found = []
        for pattern in duplicate_patterns:
            matches = list(self.repo_root.glob(f"**/{pattern}"))
            if len(matches) > 1:
                duplicates_found.append({
                    "pattern": pattern,
                    "locations": [str(m.relative_to(self.repo_root)) for m in matches]
                })
        self.results["code_duplication"] = {
            "duplicates_found": len(duplicates_found),
            "details": duplicates_found,
            "status": "âš ï¸ WARNING" if duplicates_found else "âœ… PASS"
        }
    def check_docstring_coverage(self):
        """P1: Docstring è¦†è“‹ç‡"""
        print("\nğŸ“ æª¢æŸ¥ Docstring è¦†è“‹ç‡...")
        py_files = list(self.repo_root.glob("**/*.py"))
        files_with_docstrings = 0
        for py_file in py_files:
            try:
                content = py_file.read_text()
                # æª¢æ¸¬ï¼šæª”æ¡ˆåŒ…å« docstringsï¼ˆå¯èƒ½æœ‰èª¤å ±ï¼Œå»ºè­°ä½¿ç”¨ interrogateï¼‰
                if '"""' in content or "'''" in content:
                    files_with_docstrings += 1
            except (UnicodeDecodeError, OSError, PermissionError):
                continue
        coverage = (files_with_docstrings / len(py_files) * 100) if py_files else 0
        self.results["docstring_coverage"] = {
            "total_files": len(py_files),
            "files_with_docstrings": files_with_docstrings,
            "coverage": f"{coverage:.1f}%",
            "status": "âœ… PASS" if coverage >= 85 else "âš ï¸ WARNING",
            "target": "85%"
        }
    def check_non_ascii_filenames(self):
        """P1: é ASCII æª”åæª¢æŸ¥"""
        print("\nğŸŒ æª¢æŸ¥é ASCII æª”å...")
        non_ascii_files = []
        for path in self.repo_root.rglob("*"):
            if path.is_file():
                try:
                    path.name.encode('ascii')
                except UnicodeEncodeError:
                    non_ascii_files.append(str(path.relative_to(self.repo_root)))
        self.results["non_ascii_filenames"] = {
            "count": len(non_ascii_files),
            "files": non_ascii_files[:10],  # åªé¡¯ç¤ºå‰ 10 å€‹
            "status": "âš ï¸ WARNING" if non_ascii_files else "âœ… PASS"
        }
    def check_console_logs(self):
        """P1: Console.log æª¢æŸ¥"""
        print("\nğŸ–¥ï¸  æª¢æŸ¥ console.log ä½¿ç”¨...")
        files_with_console = []
        for ext in [".ts", ".tsx", ".js", ".jsx"]:
            for file_path in self.repo_root.glob(f"**/*{ext}"):
                try:
                    content = file_path.read_text()
                    if "console.log" in content:
                        files_with_console.append(str(file_path.relative_to(self.repo_root)))
                except (UnicodeDecodeError, OSError, PermissionError):
                    continue
        self.results["console_logs"] = {
            "count": len(files_with_console),
            "files": files_with_console[:20],  # åªé¡¯ç¤ºå‰ 20 å€‹
            "status": "âš ï¸ WARNING" if files_with_console else "âœ… PASS"
        }
    def check_eval_usage(self):
        """P1: eval() ä½¿ç”¨æª¢æŸ¥"""
        print("\nâš ï¸  æª¢æŸ¥ ast.literal_eval() ä½¿ç”¨...")
        files_with_eval = []
        for ext in [".py", ".ts", ".js"]:
            for file_path in self.repo_root.glob(f"**/*{ext}"):
                try:
                    content = file_path.read_text()
                    if "ast.literal_eval(" in content:
                        files_with_eval.append(str(file_path.relative_to(self.repo_root)))
                except (UnicodeDecodeError, OSError, PermissionError):
                    continue
        self.results["eval_usage"] = {
            "count": len(files_with_eval),
            "files": files_with_eval,
            "status": "âš ï¸ WARNING" if files_with_eval else "âœ… PASS"
        }
        # å…ˆç”¢ç”Ÿç¶“éå®‰å…¨éæ¿¾çš„çµæœï¼Œä»¥é¿å…åœ¨å ±å‘Šä¸­å„²å­˜æ˜æ–‡æ•æ„Ÿè³‡è¨Š
        sanitized_results = self._sanitize_results_for_report(self.results)
    def generate_report(self):
        """ç”Ÿæˆå ±å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š è‡ªå‹•åŒ–å“è³ªæª¢æŸ¥å ±å‘Š")
        print("="*80)
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": {},
            "details": sanitized_results
        }
        # çµ±è¨ˆç‹€æ…‹
        total_checks = len(self.results)
        passed = sum(1 for r in self.results.values() if r.get("status") == "âœ… PASS")
        warnings = sum(1 for r in self.results.values() if r.get("status") == "âš ï¸ WARNING")
        report["summary"] = {
            "total_checks": total_checks,
            "passed": passed,
            "warnings": warnings,
            "pass_rate": f"{(passed/total_checks*100):.1f}%"
        }
        # è¼¸å‡ºåˆ°è¢å¹•
        print(f"\nç¸½æª¢æŸ¥é …ç›®: {total_checks}")
        print(f"é€šé: {passed}")
        print(f"è­¦å‘Š: {warnings}")
        print(f"é€šéç‡: {report['summary']['pass_rate']}")
        print("\nè©³ç´°çµæœ:")
        for check_name, result in self.results.items():
            print(f"\n{check_name.upper()}: {result.get('status', 'N/A')}")

            # For security-related results, avoid logging any potentially sensitive
            # details that may be derived from secret-scanning tools. Only emit a
            # high-level indication of whether secrets were detected.
            if check_name == "security":
                secrets_detected = result.get("secrets_detected")
                if secrets_detected is True:
                    print("  - summary: Potential secrets were detected. Please review the repository with appropriate privileges.")
                elif secrets_detected is False:
                    print("  - summary: No obvious secrets were detected by the scanner.")
                else:
                    print("  - summary: Security scan result unavailable or inconclusive.")
                # Skip generic field-by-field logging for security results to prevent
                # accidental exposure of sensitive information.
                continue

            def format_safe_value(key: str, value: Any) -> str:
                """Format values for logging without exposing sensitive data."""
                # Explicitly redact known-sensitive keys
                if key in ["secrets", "tokens", "passwords", "keys", "credentials"]:
                    return "[REDACTED FOR SECURITY]"
                # For collections, log only high-level summary information
                try:
                    if isinstance(value, dict):
                        return f"[Dictionary with {len(value)} entries]"
                    if isinstance(value, (list, tuple, set)):
                        return f"[Sequence with {len(value)} items]"
                except TypeError:
                    # Fallback if len() is not supported
                    return "[Non-scalar data]"
                # For other (typically scalar) values, log directly
                # Large string values are truncated to avoid accidental leaks
                text = str(value)
                if len(text) > 200:
                    return text[:197] + "..."
                return text

            for key, value in result.items():
                if key == "status":
                    continue
                safe_value = format_safe_value(key, value)
                print(f"  - {key}: {safe_value}")
        # å„²å­˜ JSON å ±å‘Š
        report_file = self.repo_root / "auto-quality-report.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… å ±å‘Šå·²å„²å­˜è‡³: {report_file}")
        # ç”Ÿæˆ Markdown å ±å‘Šï¼ˆåŒæ¨£ä½¿ç”¨å·²éæ¿¾çš„çµæœï¼‰

        self.generate_markdown_report(report)
    def generate_markdown_report(self, report: Dict):
        """ç”Ÿæˆ Markdown æ ¼å¼å ±å‘Š"""
        md_file = self.repo_root / "AUTO-QUALITY-REPORT.md"
        with open(md_file, "w", encoding="utf-8") as f:
            f.write("# è‡ªå‹•åŒ–å“è³ªæª¢æŸ¥å ±å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ™‚é–“**: {report['timestamp']}\n\n")
            f.write("## ğŸ“Š ç¸½è¦½\n\n")
            f.write(f"- ç¸½æª¢æŸ¥é …ç›®: {report['summary']['total_checks']}\n")
            f.write(f"- âœ… é€šé: {report['summary']['passed']}\n")
            f.write(f"- âš ï¸ è­¦å‘Š: {report['summary']['warnings']}\n")
            f.write(f"- é€šéç‡: {report['summary']['pass_rate']}\n\n")
            f.write("## ğŸ“‹ è©³ç´°çµæœ\n\n")
            # åƒ…ä½¿ç”¨å·²è¢« generate_report éæ¿¾å¾Œçš„ details
            for check_name, result in report["details"].items():
                f.write(f"### {check_name.replace('_', ' ').title()}\n\n")
                status = result.get("status", "N/A") if isinstance(result, dict) else "N/A"
                f.write(f"**ç‹€æ…‹**: {status}\n\n")
                if isinstance(result, dict):
                    for key, value in result.items():
                        if key == "status":
                            continue
                        # åœ¨æ­¤éšæ®µï¼Œæ•æ„Ÿè³‡æ–™å·²åœ¨ _sanitize_results_for_report ä¸­é®ç½©ï¼Œ
                        # å› æ­¤å¯ä»¥ç›´æ¥è¼¸å‡ºã€‚
                        if isinstance(value, dict) and "count" in value and "note" in value:
                            # é€™æ˜¯ä¾†è‡ªæ¸…å–®çš„æ‘˜è¦è³‡è¨Š
                            f.write(f"- **{key}**: {value['count']} é … ({value['note']})\n")
                        else:
                            f.write(f"- **{key}**: {value}\n")
                f.write("\n")
            f.write("## ğŸ¯ å»ºè­°è¡Œå‹•\n\n")
            if report.get("details", {}).get("security", {}).get("secrets_detected"):
                f.write("1. **é«˜å„ªå…ˆç´š**: å¯©æŸ¥ä¸¦ç§»é™¤ç¡¬ç·¨ç¢¼çš„ç§˜å¯†\n")
            # å®‰å…¨åœ°è§£æå‹åˆ¥æç¤ºè¦†è“‹ç‡
            type_hint_coverage_str = self.results.get("python_quality", {}).get("type_hint_coverage", "0%")
            try:
                type_hint_coverage = float(type_hint_coverage_str.rstrip("%"))
                if type_hint_coverage < 90:
                    f.write("2. **é«˜å„ªå…ˆç´š**: æå‡ Python å‹åˆ¥æç¤ºè¦†è“‹ç‡è‡³ 90%+\n")
            except (ValueError, AttributeError):
                pass
            if self.results.get("code_duplication", {}).get("duplicates_found", 0) > 0:
                f.write("3. **é«˜å„ªå…ˆç´š**: ç§»é™¤é‡è¤‡çš„ç¨‹å¼ç¢¼æ¨¡çµ„\n")
            if self.results.get("non_ascii_filenames", {}).get("count", 0) > 0:
                f.write("4. **ä¸­å„ªå…ˆç´š**: é‡æ–°å‘½åé ASCII æª”å\n")
            if self.results.get("console_logs", {}).get("count", 0) > 0:
                f.write("5. **ä¸­å„ªå…ˆç´š**: æ›¿æ› console.log ç‚ºçµæ§‹åŒ–æ—¥èªŒ\n")
            f.write("\nè©³ç´°æ”¹é€²è¨ˆåŠƒè«‹åƒè€ƒ: [PR-1-ACTION-PLAN.md](./PR-1-ACTION-PLAN.md)\n")
        print(f"âœ… Markdown å ±å‘Šå·²å„²å­˜è‡³: {md_file}")
def main():
    parser = argparse.ArgumentParser(description="è‡ªå‹•åŒ–ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥")
    parser.add_argument(
        "--repo-root",
        type=Path,
        default=Path.cwd(),
        help="å€‰åº«æ ¹ç›®éŒ„è·¯å¾‘"
    )
    args = parser.parse_args()
    checker = QualityChecker(args.repo_root)
    checker.run_all_checks()
if __name__ == "__main__":
    main()
