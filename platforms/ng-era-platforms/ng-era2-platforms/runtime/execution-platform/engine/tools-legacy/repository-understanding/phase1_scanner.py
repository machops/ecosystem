# @ECO-governed
# @ECO-layer: GL90-99
# @ECO-semantic: archive-tools
# @ECO-audit-trail: ../../engine/gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
# GL Unified Architecture Governance Framework Activated
#
# @ECO-governed
# @ECO-layer: gl-platform.governance
# @ECO-semantic: phase1_scanner
# @ECO-audit-trail: ../../engine/gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
#!/usr/bin/env python3
"""
ç¬¬ä¸€éšæ®µï¼šå„²å­˜åº«æƒæå’ŒçŸ¥è­˜åº«å»ºç«‹
"""
# MNGA-002: Import organization needs review
import os
import json
import yaml
from pathlib import Path
from collections import defaultdict
from datetime import datetime
class RepositoryScanner:
    def __init__(self, root_path=None):
        # Default to repository root (3 levels up from this script's location)
        if root_path is None:
            script_dir = Path(__file__).parent.absolute()
            root_path = script_dir.parent.parent.parent  # workspace/tools/repository-understanding -> workspace -> root
        self.root_path = Path(root_path)
        self.knowledge_base = {
            'metadata': {
                'scan_date': datetime.now().isoformat(),
                'phase': 'Phase 1 - Initial Scan',
                'scanner_version': '1.0.0'
            },
            'directories': {},
            'files': {},
            'relationships': {},
            'statistics': {},
            'critical_files': [],
            'configurations': {}
        }
    def scan(self):
        """åŸ·è¡Œå®Œæ•´æƒæ"""
        print("ğŸ” é–‹å§‹æƒæå„²å­˜åº«...")
        print(f"ğŸ“ æ ¹ç›®éŒ„: {self.root_path.absolute()}")
        # æª¢æŸ¥æ ¹ç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not self.root_path.exists():
            print(f"âŒ éŒ¯èª¤ï¼šæ ¹ç›®éŒ„ä¸å­˜åœ¨: {self.root_path}")
            return False
        # æƒæç›®éŒ„çµæ§‹
        self.scan_directories()
        # æƒææª”æ¡ˆ
        self.scan_files()
        # åˆ†æé…ç½®æª”æ¡ˆ
        self.analyze_configurations()
        # å»ºç«‹é—œä¿‚åœ–
        self.build_relationships()
        # ç”Ÿæˆçµ±è¨ˆ
        self.generate_statistics()
        # è­˜åˆ¥é—œéµæª”æ¡ˆ
        self.identify_critical_files()
        print("âœ… æƒæå®Œæˆï¼")
        return True
    def scan_directories(self):
        """æƒæç›®éŒ„çµæ§‹"""
        print("ğŸ“ æƒæç›®éŒ„çµæ§‹...")
        for root, dirs, files in os.walk(self.root_path):
            root_path = Path(root)
            # è·³ééš±è—ç›®éŒ„å’ŒæŸäº›ç³»çµ±ç›®éŒ„
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules', '.git']]
            if root_path != self.root_path:
                rel_path = root_path.relative_to(self.root_path)
                dir_info = {
                    'path': str(rel_path),
                    'absolute_path': str(root_path),
                    'parent': str(rel_path.parent) if rel_path.parent != Path('.') else 'root',
                    'subdirectories': dirs.copy(),
                    'file_count': len(files),
                    'purpose': self.classify_directory_purpose(root_path, dirs, files),
                    'depth': len(rel_path.parts)
                }
                self.knowledge_base['directories'][str(rel_path)] = dir_info
        print(f"âœ… æƒæå®Œæˆ: {len(self.knowledge_base['directories'])} å€‹ç›®éŒ„")
    def classify_directory_purpose(self, dir_path, subdirs, files):
        """åˆ†é¡ç›®éŒ„ç”¨é€”"""
        dir_name = dir_path.name.lower()
        path_parts = str(dir_path).lower().split(os.sep)
        # åŸºæ–¼ç›®éŒ„åç¨±åˆ†é¡
        purpose_map = {
            'src': 'source_code',
            'source': 'source_code',
            'lib': 'source_code',
            'library': 'source_code',
            'bin': 'executable',
            'sbin': 'system_executable',
            'etc': 'configuration',
            'config': 'configuration',
            'configuration': 'configuration',
            'docs': 'documentation',
            'doc': 'documentation',
            'documentation': 'documentation',
            'test': 'testing',
            'tests': 'testing',
            'spec': 'testing',
            'specs': 'testing',
            'scripts': 'scripts',
            'tools': 'tools',
            'utils': 'utilities',
            'workspace': 'workspace',
            'work': 'workspace',
            'var': 'variable_data',
            'tmp': 'temporary',
            'temp': 'temporary',
            'opt': 'optional_software',
            'srv': 'service_data',
            'home': 'user_home',
            'root': 'root_home'
        }
        if dir_name in purpose_map:
            return purpose_map[dir_name]
        # åŸºæ–¼è·¯å¾‘åˆ†é¡
        if 'namespace' in path_parts:
            return 'namespace_organization'
        elif 'controlplane' in path_parts:
            return 'control_plane'
        elif 'gl-platform.governance' in path_parts:
            return 'gl-platform.governance'
        elif 'github' in path_parts:
            return 'ci_cd'
        elif '.github' in path_parts:
            return 'ci_cd'
        # åŸºæ–¼å…§å®¹æ¨æ–·
        if any(f.endswith('.py') for f in files):
            return 'python_code'
        elif any(f.endswith('.js') or f.endswith('.ts') for f in files):
            return 'javascript_code'
        elif any(f.endswith('.yaml') or f.endswith('.json') for f in files):
            return 'configuration'
        elif any(f.endswith('.md') for f in files):
            return 'documentation'
        return 'unknown'
    def scan_files(self):
        """æƒææª”æ¡ˆ"""
        print("ğŸ“„ æƒææª”æ¡ˆ...")
        for root, dirs, files in os.walk(self.root_path):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules', '.git']]
            root_path = Path(root)
            for file in files:
                if file.startswith('.'):
                    continue
                file_path = root_path / file
                rel_path = file_path.relative_to(self.root_path)
                try:
                    file_info = {
                        'name': file,
                        'path': str(rel_path),
                        'directory': str(rel_path.parent),
                        'extension': file_path.suffix.lower(),
                        'size': file_path.stat().st_size,
                        'type': self.classify_file_type(file_path.suffix),
                        'is_executable': os.access(file_path, os.X_OK),
                        'is_critical': self.is_critical_file(file_path)
                    }
                    self.knowledge_base['files'][str(rel_path)] = file_info
                    if file_info['is_critical']:
                        self.knowledge_base['critical_files'].append(str(rel_path))
                except Exception as e:
                    print(f"âš ï¸  è­¦å‘Šï¼šç„¡æ³•è®€å–æª”æ¡ˆ {file_path}: {e}")
        print(f"âœ… æƒæå®Œæˆ: {len(self.knowledge_base['files'])} å€‹æª”æ¡ˆ")
    def classify_file_type(self, extension):
        """åˆ†é¡æª”æ¡ˆé¡å‹"""
        ext_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.jsx': 'react',
            '.tsx': 'react',
            '.json': 'json',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.toml': 'toml',
            '.md': 'markdown',
            '.txt': 'text',
            '.sh': 'shell',
            '.bash': 'shell',
            '.zsh': 'shell',
            '.env': 'environment',
            '.gitignore': 'git',
            '.dockerignore': 'docker',
            'dockerfile': 'docker',
            'makefile': 'make',
            '.cfg': 'config',
            '.conf': 'config',
            '.ini': 'config',
            '.lock': 'lock',
            '.sum': 'checksum',
            '.pem': 'certificate',
            '.key': 'key',
            '.crt': 'certificate'
        }
        return ext_map.get(extension.lower(), 'unknown')
    def is_critical_file(self, file_path):
        """åˆ¤æ–·æ˜¯å¦ç‚ºé—œéµæª”æ¡ˆ"""
        critical_patterns = [
            'makefile',
            'dockerfile',
            '.env',
            'secrets',
            'config',
            'bootstrap',
            'main',
            'init',
            'setup',
            'requirements',
            'package.json',
            'tsconfig',
            'pyproject'
        ]
        file_name = file_path.name.lower()
        return any(pattern in file_name for pattern in critical_patterns)
    def analyze_configurations(self):
        """åˆ†æé…ç½®æª”æ¡ˆ"""
        print("âš™ï¸  åˆ†æé…ç½®æª”æ¡ˆ...")
        for file_path, file_info in self.knowledge_base['files'].items():
            if file_info['type'] in ['yaml', 'json', 'toml', 'config']:
                try:
                    full_path = self.root_path / file_path
                    if full_path.exists() and full_path.stat().st_size < 100000:  # åªåˆ†æå°æ–¼100KBçš„æª”æ¡ˆ
                        config_data = self.parse_config_file(full_path, file_info['type'])
                        if config_data:
                            self.knowledge_base['configurations'][file_path] = config_data
                except Exception as e:
                    print(f"âš ï¸  è­¦å‘Šï¼šç„¡æ³•è§£æé…ç½®æª”æ¡ˆ {file_path}: {e}")
        print(f"âœ… åˆ†æå®Œæˆ: {len(self.knowledge_base['configurations'])} å€‹é…ç½®æª”æ¡ˆ")
    def parse_config_file(self, file_path, file_type):
        """è§£æé…ç½®æª”æ¡ˆ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                if file_type in ['yaml', 'yml']:
                    return yaml.safe_load(f)
                elif file_type == 'json':
                    return json.load(f)
                else:
                    # å°æ–¼å…¶ä»–é¡å‹ï¼Œåªè¨˜éŒ„åŸºæœ¬è³‡è¨Š
                    return {
                        'type': file_type,
                        'size': file_path.stat().st_size,
                        'note': 'Content not parsed for safety'
                    }
        except Exception:
            return {
                'type': file_type,
                'error': 'Parse error',
                'note': 'File exists but could not be parsed'
            }
    def build_relationships(self):
        """å»ºç«‹æª”æ¡ˆé—œä¿‚åœ–"""
        print("ğŸ”— å»ºç«‹æª”æ¡ˆé—œä¿‚åœ–...")
        # å»ºç«‹ç›®éŒ„åˆ°æª”æ¡ˆçš„é—œä¿‚
        for dir_path, dir_info in self.knowledge_base['directories'].items():
            dir_info['files'] = []
            for file_path, file_info in self.knowledge_base['files'].items():
                if file_info['directory'] == dir_path:
                    dir_info['files'].append(file_path)
        # å»ºç«‹æª”æ¡ˆé¡å‹çµ±è¨ˆ
        type_counts = defaultdict(int)
        for file_info in self.knowledge_base['files'].values():
            type_counts[file_info['type']] += 1
        self.knowledge_base['relationships']['file_types'] = dict(type_counts)
        print("âœ… é—œä¿‚åœ–å»ºç«‹å®Œæˆ")
    def generate_statistics(self):
        """ç”Ÿæˆçµ±è¨ˆè³‡è¨Š"""
        print("ğŸ“Š ç”Ÿæˆçµ±è¨ˆè³‡è¨Š...")
        stats = {
            'total_directories': len(self.knowledge_base['directories']),
            'total_files': len(self.knowledge_base['files']),
            'critical_files_count': len(self.knowledge_base['critical_files']),
            'configurations_count': len(self.knowledge_base['configurations']),
            'directory_purposes': defaultdict(int),
            'file_types': defaultdict(int),
            'total_size': 0
        }
        for dir_info in self.knowledge_base['directories'].values():
            stats['directory_purposes'][dir_info['purpose']] += 1
        for file_info in self.knowledge_base['files'].values():
            stats['file_types'][file_info['type']] += 1
            stats['total_size'] += file_info['size']
        # è½‰æ› defaultdict ç‚º dict
        stats['directory_purposes'] = dict(stats['directory_purposes'])
        stats['file_types'] = dict(stats['file_types'])
        self.knowledge_base['statistics'] = stats
        print("âœ… çµ±è¨ˆè³‡è¨Šç”Ÿæˆå®Œæˆ")
    def identify_critical_files(self):
        """è­˜åˆ¥é—œéµæª”æ¡ˆ"""
        print("ğŸ¯ è­˜åˆ¥é—œéµæª”æ¡ˆ...")
        critical_categories = {
            'bootstrap': [],
            'configuration': [],
            'security': [],
            'build': [],
            'entry_points': []
        }
        for file_path, file_info in self.knowledge_base['files'].items():
            file_name = file_info['name'].lower()
            if 'bootstrap' in file_name or 'root' in file_name:
                critical_categories['bootstrap'].append(file_path)
            elif file_info['type'] in ['yaml', 'json', 'toml', 'config']:
                critical_categories['configuration'].append(file_path)
            elif 'secret' in file_name or 'key' in file_name or 'auth' in file_name:
                critical_categories['security'].append(file_path)
            elif file_name in ['makefile', 'dockerfile', 'build.sh']:
                critical_categories['build'].append(file_path)
            elif file_name in ['main.py', 'main.js', 'index.js', 'app.py']:
                critical_categories['entry_points'].append(file_path)
        self.knowledge_base['critical_files_by_category'] = critical_categories
        print(f"âœ… è­˜åˆ¥å®Œæˆ: {len(self.knowledge_base['critical_files'])} å€‹é—œéµæª”æ¡ˆ")
    def save_knowledge_base(self, filename='knowledge_base.json'):
        """ä¿å­˜çŸ¥è­˜åº«"""
        print(f"ğŸ’¾ ä¿å­˜çŸ¥è­˜åº«åˆ° {filename}...")
        # æ¸…ç†ç„¡æ³•åºåˆ—åŒ–çš„å°è±¡
        clean_kb = self._clean_for_json(self.knowledge_base)
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(clean_kb, f, indent=2, ensure_ascii=False)
        print("âœ… çŸ¥è­˜åº«å·²ä¿å­˜")
        return filename
    def _clean_for_json(self, obj):
        """æ¸…ç†å°è±¡ä»¥ç¢ºä¿å¯ä»¥ JSON åºåˆ—åŒ–"""
        if isinstance(obj, dict):
            return {k: self._clean_for_json(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._clean_for_json(item) for item in obj]
        elif isinstance(obj, (str, int, float, bool)) or obj is None:
            return obj
        else:
            # å°‡å…¶ä»–é¡å‹è½‰æ›ç‚ºå­—ç¬¦ä¸²
            return str(obj)
    def generate_report(self, filename='phase1_report.md'):
        """ç”Ÿæˆå ±å‘Š"""
        print(f"ğŸ“ ç”Ÿæˆå ±å‘Šåˆ° {filename}...")
        stats = self.knowledge_base['statistics']
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("# ç¬¬ä¸€éšæ®µï¼šå„²å­˜åº«æƒæå ±å‘Š\n\n")
            f.write(f"**æƒææ—¥æœŸ**: {self.knowledge_base['metadata']['scan_date']}\n")
            f.write(f"**éšæ®µ**: {self.knowledge_base['metadata']['phase']}\n\n")
            f.write("## ğŸ“Š çµ±è¨ˆæ‘˜è¦\n\n")
            f.write(f"- **ç¸½ç›®éŒ„æ•¸**: {stats['total_directories']}\n")
            f.write(f"- **ç¸½æª”æ¡ˆæ•¸**: {stats['total_files']}\n")
            f.write(f"- **é—œéµæª”æ¡ˆæ•¸**: {stats['critical_files_count']}\n")
            f.write(f"- **é…ç½®æª”æ¡ˆæ•¸**: {stats['configurations_count']}\n")
            f.write(f"- **ç¸½å¤§å°**: {stats['total_size'] / 1024:.2f} KB\n\n")
            f.write("## ğŸ“ ç›®éŒ„ç”¨é€”åˆ†ä½ˆ\n\n")
            f.write("| ç”¨é€” | æ•¸é‡ |\n")
            f.write("|------|------|\n")
            for purpose, count in sorted(stats['directory_purposes'].items(), key=lambda x: x[1], reverse=True):
                f.write(f"| {purpose} | {count} |\n")
            f.write("\n")
            f.write("## ğŸ“„ æª”æ¡ˆé¡å‹åˆ†ä½ˆ\n\n")
            f.write("| é¡å‹ | æ•¸é‡ |\n")
            f.write("|------|------|\n")
            for file_type, count in sorted(stats['file_types'].items(), key=lambda x: x[1], reverse=True):
                f.write(f"| {file_type} | {count} |\n")
            f.write("\n")
            f.write("## ğŸ¯ é—œéµæª”æ¡ˆ\n\n")
            f.write("### æŒ‰é¡åˆ¥åˆ†é¡\n\n")
            for category, files in self.knowledge_base['critical_files_by_category'].items():
                f.write(f"#### {category.capitalize()}\n\n")
                for file_path in files[:10]:  # åªé¡¯ç¤ºå‰10å€‹
                    f.write(f"- `{file_path}`\n")
                if len(files) > 10:
                    f.write(f"- ... å’Œå…¶ä»– {len(files) - 10} å€‹æª”æ¡ˆ\n")
                f.write("\n")
        print("âœ… å ±å‘Šå·²ç”Ÿæˆ")
        return filename
def main():
    """ä¸»ç¨‹å¼"""
    print("="*60)
    print("ğŸš€ ç¬¬ä¸€éšæ®µï¼šå„²å­˜åº«æƒæå’ŒçŸ¥è­˜åº«å»ºç«‹")
    print("="*60 + "\n")
    # å‰µå»ºæƒæå™¨
    scanner = RepositoryScanner()
    # åŸ·è¡Œæƒæ
    if scanner.scan():
        # ä¿å­˜çŸ¥è­˜åº«
        kb_file = scanner.save_knowledge_base('knowledge_base.json')
        # ç”Ÿæˆå ±å‘Š
        report_file = scanner.generate_report('phase1_report.md')
        print("\n" + "="*60)
        print("âœ… ç¬¬ä¸€éšæ®µå®Œæˆï¼")
        print("="*60)
        print(f"ğŸ“ çŸ¥è­˜åº«: {kb_file}")
        print(f"ğŸ“„ å ±å‘Š: {report_file}")
        print("="*60)
        return True
    else:
        print("âŒ æƒæå¤±æ•—")
        return False
if __name__ == '__main__':
    main()