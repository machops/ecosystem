# @ECO-governed
# @ECO-layer: GL90-99
# @ECO-semantic: archive-tools
# @ECO-audit-trail: ../../engine/gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
# GL Unified Architecture Governance Framework Activated
#
# @ECO-governed
# @ECO-layer: gl-platform.governance
# @ECO-semantic: phase4_learning_system
# @ECO-audit-trail: ../../engine/gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
#!/usr/bin/env python3
"""
ç¬¬å››éšæ®µï¼šæŒçºŒå­¸ç¿’æ©Ÿåˆ¶
"""
# MNGA-002: Import organization needs review
import json
import os
import shutil
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Dict, Optional
import hashlib
class ContinuousLearningSystem:
    def __init__(self, knowledge_base_path='knowledge_base.json'):
        self.knowledge_base_path = knowledge_base_path
        self.knowledge_base = self.load_knowledge_base()
        self.learning_log = []
        self.operation_feedback = []
        self.knowledge_updates = []
        self.best_practices = []
        self.error_patterns = defaultdict(int)
    def load_knowledge_base(self):
        """è¼‰å…¥çŸ¥è­˜åº«"""
        try:
            with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ ç„¡æ³•è¼‰å…¥çŸ¥è­˜åº«: {e}")
            return None
    def record_operation_feedback(self, operation: Dict, success: bool, feedback: str = ""):
        """è¨˜éŒ„æ“ä½œå›é¥‹"""
        feedback_entry = {
            'timestamp': datetime.now().isoformat(),
            'operation': operation,
            'success': success,
            'feedback': feedback,
            'learned': False
        }
        self.operation_feedback.append(feedback_entry)
        # åˆ†æå›é¥‹ä¸¦å­¸ç¿’
        if not success:
            self.analyze_failure_pattern(operation, feedback)
        print(f"ğŸ“ æ“ä½œå›é¥‹å·²è¨˜éŒ„: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
        return feedback_entry
    def analyze_failure_pattern(self, operation: Dict, feedback: str):
        """åˆ†æå¤±æ•—æ¨¡å¼"""
        operation_type = operation.get('operation', '')
        target = operation.get('target', '')
        # è¨˜éŒ„å¤±æ•—æ¨¡å¼
        pattern_key = f"{operation_type}:{Path(target).suffix if '.' in target else 'dir'}"
        self.error_patterns[pattern_key] += 1
        # æª¢æŸ¥æ˜¯å¦æ˜¯é‡è¤‡éŒ¯èª¤
        if self.error_patterns[pattern_key] >= 3:
            self.generate_best_practice(operation, feedback)
    def generate_best_practice(self, operation: Dict, error_feedback: str):
        """ç”Ÿæˆæœ€ä½³å¯¦è¸"""
        operation_type = operation.get('operation', '')
        target = operation.get('target', '')
        best_practice = {
            'id': hashlib.md5(f"{operation_type}:{target}:{datetime.now().isoformat()}".encode()).hexdigest()[:8],
            'timestamp': datetime.now().isoformat(),
            'operation_type': operation_type,
            'target_pattern': self.extract_pattern(target),
            'error': error_feedback,
            'recommendation': self.generate_recommendation(operation, error_feedback),
            'usage_count': 0
        }
        self.best_practices.append(best_practice)
        print(f"ğŸ’¡ ç”Ÿæˆæœ€ä½³å¯¦è¸: {best_practice['id']}")
    def extract_pattern(self, target: str) -> str:
        """æå–ç›®æ¨™æ¨¡å¼"""
        path = Path(target)
        # æå–æª”æ¡ˆé¡å‹
        if '.' in path.name:
            return f"*{path.suffix}"
        # æå–ç›®éŒ„æ¨¡å¼
        parts = path.parts
        if len(parts) >= 2:
            return f"*/{parts[-1]}"
        return str(path)
    def generate_recommendation(self, operation: Dict, error_feedback: str) -> str:
        """ç”Ÿæˆå»ºè­°"""
        operation_type = operation.get('operation', '')
        operation.get('target', '')
        recommendations = {
            'delete': [
                "âš ï¸  åˆªé™¤å‰å‹™å¿…ç¢ºèªæª”æ¡ˆä¸å†è¢«å…¶ä»–æª”æ¡ˆå¼•ç”¨",
                "ğŸ” ä½¿ç”¨æŸ¥è©¢ç³»çµ±æª¢æŸ¥ä¾è³´é—œä¿‚",
                "ğŸ’¾ ç¢ºèªæœ‰é©ç•¶çš„å‚™ä»½",
                "ğŸ“‹ åœ¨æ¸¬è©¦ç’°å¢ƒä¸­å…ˆé©—è­‰å½±éŸ¿"
            ],
            'modify': [
                "ğŸ” å…ˆæŸ¥è©¢æª”æ¡ˆä¸Šä¸‹æ–‡äº†è§£ç”¨é€”",
                "âš ï¸  æª¢æŸ¥æ˜¯å¦ç‚ºé—œéµæª”æ¡ˆ",
                "ğŸ“ è¨˜éŒ„ä¿®æ”¹åŸå› å’Œå½±éŸ¿",
                "âœ… ä¿®æ”¹å¾ŒåŸ·è¡Œç›¸é—œæ¸¬è©¦"
            ],
            'create': [
                "ğŸ“ ç¢ºèªæª”æ¡ˆæ”¾ç½®åœ¨æ­£ç¢ºçš„ç›®éŒ„",
                "ğŸ·ï¸  ä½¿ç”¨æ¸…æ™°çš„å‘½åè¦ç¯„",
                "ğŸ“ æ·»åŠ é©ç•¶çš„è¨»é‡‹å’Œæ–‡ä»¶",
                "ğŸ”— æ›´æ–°ç›¸é—œçš„ä¾è³´é—œä¿‚"
            ]
        }
        base_recommendations = recommendations.get(operation_type, ["ğŸ” è©³ç´°äº†è§£æ“ä½œå½±éŸ¿ç¯„åœ"])
        # æ ¹æ“šéŒ¯èª¤è¨Šæ¯æ·»åŠ ç‰¹å®šå»ºè­°
        if "æ¬Šé™" in error_feedback or "permission" in error_feedback.lower():
            base_recommendations.append("ğŸ” æª¢æŸ¥æª”æ¡ˆæ¬Šé™è¨­å®š")
        elif "ä¸å­˜åœ¨" in error_feedback or "not found" in error_feedback.lower():
            base_recommendations.append("ğŸ“‚ ç¢ºèªç›®æ¨™è·¯å¾‘æ­£ç¢ºæ€§")
        elif "é—œéµ" in error_feedback or "critical" in error_feedback.lower():
            base_recommendations.append("âš ï¸  å°é—œéµæª”æ¡ˆçš„æ“ä½œéœ€è¦é¡å¤–å¯©æŸ¥")
        return "ï¼›".join(base_recommendations)
    def get_best_practice(self, operation_type: str, target: str) -> Optional[Dict]:
        """ç²å–æœ€ä½³å¯¦è¸å»ºè­°"""
        target_pattern = self.extract_pattern(target)
        # æŸ¥æ‰¾åŒ¹é…çš„æœ€ä½³å¯¦è¸
        for practice in self.best_practices:
            if (practice['operation_type'] == operation_type and 
                self.pattern_matches(target_pattern, practice['target_pattern'])):
                practice['usage_count'] += 1
                return practice
        return None
    def pattern_matches(self, current_pattern: str, stored_pattern: str) -> bool:
        """æª¢æŸ¥æ¨¡å¼æ˜¯å¦åŒ¹é…"""
        # ç°¡å–®å¯¦ç¾ï¼šç²¾ç¢ºåŒ¹é…æˆ–è¬ç”¨å­—å…ƒåŒ¹é…
        if current_pattern == stored_pattern:
            return True
        if stored_pattern.startswith('*') and current_pattern.endswith(stored_pattern[1:]):
            return True
        if current_pattern.startswith('*') and stored_pattern.endswith(current_pattern[1:]):
            return True
        return False
    def update_knowledge_base(self, updates: Dict):
        """æ›´æ–°çŸ¥è­˜åº«"""
        update_entry = {
            'timestamp': datetime.now().isoformat(),
            'updates': updates,
            'applied': False
        }
        try:
            # æ‡‰ç”¨æ›´æ–°
            for key, value in updates.items():
                if key in self.knowledge_base:
                    if isinstance(self.knowledge_base[key], dict) and isinstance(value, dict):
                        self.knowledge_base[key].update(value)
                    else:
                        self.knowledge_base[key] = value
                else:
                    self.knowledge_base[key] = value
            update_entry['applied'] = True
            self.knowledge_updates.append(update_entry)
            # ä¿å­˜æ›´æ–°å¾Œçš„çŸ¥è­˜åº«
            self.save_knowledge_base()
            print(f"âœ… çŸ¥è­˜åº«å·²æ›´æ–°: {len(updates)} é …æ›´æ–°")
        except Exception as e:
            print(f"âŒ çŸ¥è­˜åº«æ›´æ–°å¤±æ•—: {e}")
            update_entry['error'] = str(e)
        return update_entry
    def save_knowledge_base(self, backup=True):
        """ä¿å­˜çŸ¥è­˜åº«"""
        if backup:
            # å‰µå»ºå‚™ä»½
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = f"knowledge_base_backup_{timestamp}.json"
            shutil.copy2(self.knowledge_base_path, backup_path)
            print(f"ğŸ’¾ çŸ¥è­˜åº«å‚™ä»½å·²å‰µå»º: {backup_path}")
        # ä¿å­˜ç•¶å‰çŸ¥è­˜åº«
        try:
            with open(self.knowledge_base_path, 'w', encoding='utf-8') as f:
                json.dump(self.knowledge_base, f, indent=2, ensure_ascii=False)
            print("âœ… çŸ¥è­˜åº«å·²ä¿å­˜")
        except Exception as e:
            print(f"âŒ çŸ¥è­˜åº«ä¿å­˜å¤±æ•—: {e}")
    def scan_for_changes(self):
        """æƒææª”æ¡ˆç³»çµ±è®ŠåŒ–"""
        print("\nğŸ” æƒææª”æ¡ˆç³»çµ±è®ŠåŒ–...")
        changes_detected = []
        current_files = set()
        current_dirs = set()
        # æƒæç•¶å‰ç‹€æ…‹
        for root, dirs, files in os.walk('.'):
            root_path = Path(root)
            for file in files:
                if not file.startswith('.'):
                    file_path = root_path / file
                    current_files.add(str(file_path))
            for dir_name in dirs:
                if not dir_name.startswith('.') and dir_name not in ['__pycache__', 'node_modules']:
                    dir_path = root_path / dir_name
                    current_dirs.add(str(dir_path))
        # æ¯”è¼ƒè®ŠåŒ–
        known_files = set(self.knowledge_base.get('files', {}).keys())
        known_dirs = set(self.knowledge_base.get('directories', {}).keys())
        new_files = current_files - known_files
        deleted_files = known_files - current_files
        new_dirs = current_dirs - known_dirs
        deleted_dirs = known_dirs - current_dirs
        if new_files:
            changes_detected.append({
                'type': 'new_files',
                'count': len(new_files),
                'items': list(new_files)[:10]
            })
        if deleted_files:
            changes_detected.append({
                'type': 'deleted_files',
                'count': len(deleted_files),
                'items': list(deleted_files)[:10]
            })
        if new_dirs:
            changes_detected.append({
                'type': 'new_directories',
                'count': len(new_dirs),
                'items': list(new_dirs)[:10]
            })
        if deleted_dirs:
            changes_detected.append({
                'type': 'deleted_directories',
                'count': len(deleted_dirs),
                'items': list(deleted_dirs)[:10]
            })
        if changes_detected:
            print(f"ğŸ“Š æª¢æ¸¬åˆ° {len(changes_detected)} ç¨®è®ŠåŒ–")
            for change in changes_detected:
                print(f"   - {change['type']}: {change['count']} é …")
            # è¨˜éŒ„å­¸ç¿’æ—¥èªŒ
            learning_entry = {
                'timestamp': datetime.now().isoformat(),
                'type': 'change_detection',
                'changes': changes_detected,
                'action_required': True
            }
            self.learning_log.append(learning_entry)
        else:
            print("âœ… æœªæª¢æ¸¬åˆ°è®ŠåŒ–")
        return changes_detected
    def generate_learning_report(self, filename='phase4_report.md'):
        """ç”Ÿæˆå­¸ç¿’å ±å‘Š"""
        print(f"\nğŸ“ ç”Ÿæˆå­¸ç¿’å ±å‘Šåˆ° {filename}...")
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("# ç¬¬å››éšæ®µï¼šæŒçºŒå­¸ç¿’æ©Ÿåˆ¶å ±å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¥æœŸ**: {datetime.now().isoformat()}\n")
            f.write("**éšæ®µ**: Phase 4 - Continuous Learning System\n\n")
            f.write("## ğŸ“Š å­¸ç¿’çµ±è¨ˆ\n\n")
            f.write(f"- **æ“ä½œå›é¥‹æ¬¡æ•¸**: {len(self.operation_feedback)}\n")
            f.write(f"- **æˆåŠŸæ“ä½œ**: {sum(1 for f in self.operation_feedback if f['success'])}\n")
            f.write(f"- **å¤±æ•—æ“ä½œ**: {sum(1 for f in self.operation_feedback if not f['success'])}\n")
            f.write(f"- **çŸ¥è­˜åº«æ›´æ–°æ¬¡æ•¸**: {len(self.knowledge_updates)}\n")
            f.write(f"- **æœ€ä½³å¯¦è¸æ•¸é‡**: {len(self.best_practices)}\n")
            f.write(f"- **å­¸ç¿’æ—¥èªŒæ¢ç›®**: {len(self.learning_log)}\n\n")
            f.write("## ğŸ¯ æœ€ä½³å¯¦è¸\n\n")
            if self.best_practices:
                for practice in self.best_practices:
                    f.write(f"### å¯¦è¸ #{practice['id']}\n\n")
                    f.write(f"- **æ“ä½œé¡å‹**: {practice['operation_type']}\n")
                    f.write(f"- **ç›®æ¨™æ¨¡å¼**: {practice['target_pattern']}\n")
                    f.write(f"- **éŒ¯èª¤**: {practice['error']}\n")
                    f.write(f"- **å»ºè­°**: {practice['recommendation']}\n")
                    f.write(f"- **ä½¿ç”¨æ¬¡æ•¸**: {practice['usage_count']}\n\n")
            else:
                f.write("æš«ç„¡æœ€ä½³å¯¦è¸è¨˜éŒ„\n\n")
            f.write("## ğŸ“ˆ å¤±æ•—æ¨¡å¼åˆ†æ\n\n")
            if self.error_patterns:
                f.write("| æ¨¡å¼ | æ¬¡æ•¸ |\n")
                f.write("|------|------|\n")
                for pattern, count in sorted(self.error_patterns.items(), key=lambda x: x[1], reverse=True)[:10]:
                    f.write(f"| {pattern} | {count} |\n")
            else:
                f.write("æš«ç„¡å¤±æ•—æ¨¡å¼è¨˜éŒ„\n\n")
            f.write("## ğŸ”„ å­¸ç¿’æ©Ÿåˆ¶\n\n")
            f.write("### 1. æ“ä½œå›é¥‹å¾ªç’°\n\n")
            f.write("ç³»çµ±æœƒè¨˜éŒ„æ¯æ¬¡æ“ä½œçš„çµæœå’Œå›é¥‹ï¼š\n")
            f.write("- âœ… æˆåŠŸæ“ä½œï¼šè¨˜éŒ„æˆåŠŸæ¨¡å¼å’Œæœ€ä½³å¯¦è¸\n")
            f.write("- âŒ å¤±æ•—æ“ä½œï¼šåˆ†æå¤±æ•—åŸå› ï¼Œç”Ÿæˆé é˜²æªæ–½\n\n")
            f.write("### 2. çŸ¥è­˜åº«è‡ªå‹•æ›´æ–°\n\n")
            f.write("- ğŸ“Š å®šæœŸæƒææª”æ¡ˆç³»çµ±è®ŠåŒ–\n")
            f.write("- ğŸ” è‡ªå‹•æª¢æ¸¬æ–°å¢/åˆªé™¤çš„æª”æ¡ˆå’Œç›®éŒ„\n")
            f.write("- ğŸ’¾ è‡ªå‹•å‰µå»ºå‚™ä»½ä¸¦æ›´æ–°çŸ¥è­˜åº«\n\n")
            f.write("### 3. æ™ºèƒ½å»ºè­°ç³»çµ±\n\n")
            f.write("- ğŸ’¡ åŸºæ–¼æ­·å²æ“ä½œç”Ÿæˆæœ€ä½³å¯¦è¸\n")
            f.write("- âš ï¸  è­˜åˆ¥é‡è¤‡éŒ¯èª¤æ¨¡å¼\n")
            f.write("- ğŸ¯ æä¾›å€‹æ€§åŒ–çš„æ“ä½œå»ºè­°\n\n")
        print("âœ… å­¸ç¿’å ±å‘Šå·²ç”Ÿæˆ")
        return filename
    def get_system_health(self) -> Dict:
        """ç²å–ç³»çµ±å¥åº·ç‹€æ…‹"""
        return {
            'knowledge_base_size': len(self.knowledge_base),
            'learning_active': len(self.learning_log) > 0,
            'best_practices_available': len(self.best_practices) > 0,
            'error_patterns_detected': len(self.error_patterns) > 0,
            'last_scan': self.learning_log[-1]['timestamp'] if self.learning_log else None,
            'total_learning_events': len(self.learning_log) + len(self.operation_feedback)
        }
def main():
    """ä¸»ç¨‹å¼ - æ¼”ç¤ºæŒçºŒå­¸ç¿’æ©Ÿåˆ¶"""
    print("="*60)
    print("ğŸš€ ç¬¬å››éšæ®µï¼šå»ºç«‹æŒçºŒå­¸ç¿’æ©Ÿåˆ¶")
    print("="*60 + "\n")
    # å‰µå»ºå­¸ç¿’ç³»çµ±
    learning_system = ContinuousLearningSystem()
    if not learning_system.knowledge_base:
        print("âŒ ç„¡æ³•è¼‰å…¥çŸ¥è­˜åº«ï¼Œè«‹å…ˆåŸ·è¡Œç¬¬ä¸€éšæ®µ")
        return False
    print("âœ… å­¸ç¿’ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
    # æ¼”ç¤ºå­¸ç¿’åŠŸèƒ½
    print("\n" + "="*60)
    print("ğŸ“Š æ¼”ç¤ºå­¸ç¿’åŠŸèƒ½")
    print("="*60)
    # 1. è¨˜éŒ„ä¸€äº›æ“ä½œå›é¥‹
    print("\nğŸ“ è¨˜éŒ„æ“ä½œå›é¥‹...")
    test_operations = [
        {'operation': 'read', 'target': 'test_file.txt'},
        {'operation': 'modify', 'target': 'config.yaml'},
        {'operation': 'delete', 'target': 'important_file.py'}
    ]
    for i, operation in enumerate(test_operations):
        success = i % 2 == 0  # æ¨¡æ“¬ä¸€äº›å¤±æ•—
        feedback = "æ“ä½œæˆåŠŸå®Œæˆ" if success else "æª”æ¡ˆä¸å­˜åœ¨æˆ–æ¬Šé™ä¸è¶³"
        learning_system.record_operation_feedback(operation, success, feedback)
    # 2. æƒæè®ŠåŒ–
    print("\nğŸ” æƒææª”æ¡ˆç³»çµ±è®ŠåŒ–...")
    learning_system.scan_for_changes()
    # 3. ç”Ÿæˆå ±å‘Š
    report_file = learning_system.generate_learning_report('phase4_report.md')
    # 4. é¡¯ç¤ºç³»çµ±å¥åº·ç‹€æ…‹
    health = learning_system.get_system_health()
    print("\nğŸ“Š ç³»çµ±å¥åº·ç‹€æ…‹:")
    print(f"   çŸ¥è­˜åº«å¤§å°: {health['knowledge_base_size']} é …")
    print(f"   å­¸ç¿’æ´»èº: {'æ˜¯' if health['learning_active'] else 'å¦'}")
    print(f"   æœ€ä½³å¯¦è¸: {len(learning_system.best_practices)} é …")
    print(f"   ç¸½å­¸ç¿’äº‹ä»¶: {health['total_learning_events']} æ¬¡")
    print("\n" + "="*60)
    print("âœ… ç¬¬å››éšæ®µå®Œæˆï¼")
    print("="*60)
    print(f"ğŸ“„ å ±å‘Š: {report_file}")
    print("="*60)
    return True
if __name__ == '__main__':
    main()