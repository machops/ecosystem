# @ECO-governed
# @ECO-layer: GL90-99
# @ECO-semantic: archive-tools
# @ECO-audit-trail: ../../engine/gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
# GL Unified Architecture Governance Framework Activated
#
# @ECO-governed
# @ECO-layer: gl-platform.governance
# @ECO-semantic: phase3_visualizer
# @ECO-audit-trail: ../../engine/gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
#!/usr/bin/env python3
"""
ç¬¬ä¸‰éšæ®µï¼šè¦–è¦ºåŒ–èˆ‡æŸ¥è©¢ç³»çµ±
"""
# MNGA-002: Import organization needs review
import json
from collections import defaultdict
from datetime import datetime
from typing import Dict, List
class KnowledgeVisualizer:
    def __init__(self, knowledge_base_path='knowledge_base.json'):
        self.knowledge_base_path = knowledge_base_path
        self.knowledge_base = self.load_knowledge_base()
        self.queries_log = []
    def load_knowledge_base(self):
        """è¼‰å…¥çŸ¥è­˜åº«"""
        try:
            with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ ç„¡æ³•è¼‰å…¥çŸ¥è­˜åº«: {e}")
            return None
    def query_file_context(self, file_path: str) -> Dict:
        """æŸ¥è©¢æª”æ¡ˆçš„å®Œæ•´ä¸Šä¸‹æ–‡"""
        print(f"\nğŸ” æŸ¥è©¢æª”æ¡ˆä¸Šä¸‹æ–‡: {file_path}")
        print("="*60)
        files = self.knowledge_base.get('files', {})
        directories = self.knowledge_base.get('directories', {})
        context = {
            'file_path': file_path,
            'exists': False,
            'type': None,
            'directory': None,
            'purpose': None,
            'dependencies': [],
            'affected_by': [],
            'risks': None,
            'size': None,
            'is_critical': False
        }
        if file_path in files:
            file_info = files[file_path]
            context.update({
                'exists': True,
                'type': file_info.get('type'),
                'directory': file_info.get('directory'),
                'size': file_info.get('size'),
                'is_critical': file_info.get('is_critical', False)
            })
            # ç²å–ç›®éŒ„ç”¨é€”
            if file_info.get('directory') in directories:
                dir_info = directories[file_info.get('directory')]
                context['purpose'] = dir_info.get('purpose')
            # æŸ¥æ‰¾ä¾è³´é—œä¿‚
            context['dependencies'] = self.find_dependencies(file_path)
            context['affected_by'] = self.find_affected_files(file_path)
            # è©•ä¼°é¢¨éšª
            context['risks'] = self.assess_file_risk(file_path)
        self.queries_log.append({
            'timestamp': datetime.now().isoformat(),
            'query_type': 'file_context',
            'target': file_path,
            'result': context
        })
        return context
    def find_dependencies(self, file_path: str) -> List[str]:
        """æŸ¥æ‰¾æª”æ¡ˆä¾è³´"""
        dependencies = []
        file_info = self.knowledge_base.get('files', {}).get(file_path, {})
        # ç°¡å–®å¯¦ç¾ï¼šåŸºæ–¼ç›®éŒ„å’Œæª”æ¡ˆé¡å‹
        file_type = file_info.get('type', '')
        directory = file_info.get('directory', '')
        # æŸ¥æ‰¾åŒç›®éŒ„ä¸‹çš„ç›¸é—œæª”æ¡ˆ
        files = self.knowledge_base.get('files', {})
        for other_file, other_info in files.items():
            if (other_info.get('directory') == directory and 
                other_file != file_path and
                other_info.get('type') == file_type):
                dependencies.append(other_file)
        return dependencies[:10]  # é™åˆ¶è¿”å›æ•¸é‡
    def find_affected_files(self, file_path: str) -> List[str]:
        """æŸ¥æ‰¾å—å½±éŸ¿çš„æª”æ¡ˆ"""
        affected = []
        file_info = self.knowledge_base.get('files', {}).get(file_path, {})
        # æŸ¥æ‰¾å¯èƒ½ä¾è³´æ­¤æª”æ¡ˆçš„å…¶ä»–æª”æ¡ˆ
        directory = file_info.get('directory', '')
        files = self.knowledge_base.get('files', {})
        for other_file, other_info in files.items():
            if other_info.get('directory') == directory:
                affected.append(other_file)
        return affected[:10]
    def assess_file_risk(self, file_path: str) -> str:
        """è©•ä¼°æª”æ¡ˆé¢¨éšª"""
        critical_categories = ['bootstrap', 'security', 'build', 'entry_points']
        for category in critical_categories:
            critical_files = self.knowledge_base.get('critical_files_by_category', {}).get(category, [])
            if any(file_path in f for f in critical_files):
                return f'high ({category})'
        return 'low'
    def query_directory_structure(self, directory_path: str) -> Dict:
        """æŸ¥è©¢ç›®éŒ„çµæ§‹"""
        print(f"\nğŸ” æŸ¥è©¢ç›®éŒ„çµæ§‹: {directory_path}")
        print("="*60)
        directories = self.knowledge_base.get('directories', {})
        files = self.knowledge_base.get('files', {})
        structure = {
            'directory_path': directory_path,
            'exists': False,
            'purpose': None,
            'subdirectories': [],
            'files': [],
            'total_size': 0,
            'file_types': defaultdict(int)
        }
        if directory_path in directories:
            dir_info = directories[directory_path]
            structure.update({
                'exists': True,
                'purpose': dir_info.get('purpose'),
                'subdirectories': dir_info.get('subdirectories', [])
            })
            # ç²å–è©²ç›®éŒ„ä¸‹çš„æ‰€æœ‰æª”æ¡ˆ
            for file_path, file_info in files.items():
                if file_info.get('directory') == directory_path:
                    structure['files'].append({
                        'name': file_info.get('name'),
                        'type': file_info.get('type'),
                        'size': file_info.get('size'),
                        'is_critical': file_info.get('is_critical', False)
                    })
                    structure['total_size'] += file_info.get('size', 0)
                    structure['file_types'][file_info.get('type')] += 1
        self.queries_log.append({
            'timestamp': datetime.now().isoformat(),
            'query_type': 'directory_structure',
            'target': directory_path,
            'result': structure
        })
        return structure
    def search_by_pattern(self, pattern: str, search_type: str = 'name') -> List[Dict]:
        """æ ¹æ“šæ¨¡å¼æœå°‹"""
        print(f"\nğŸ” æœå°‹: {pattern} (é¡å‹: {search_type})")
        print("="*60)
        results = []
        files = self.knowledge_base.get('files', {})
        directories = self.knowledge_base.get('directories', {})
        if search_type == 'name':
            # æœå°‹æª”æ¡ˆåç¨±
            for file_path, file_info in files.items():
                if pattern.lower() in file_info.get('name', '').lower():
                    results.append({
                        'type': 'file',
                        'path': file_path,
                        'name': file_info.get('name'),
                        'file_type': file_info.get('type'),
                        'is_critical': file_info.get('is_critical', False)
                    })
            # æœå°‹ç›®éŒ„åç¨±
            for dir_path, dir_info in directories.items():
                if pattern.lower() in dir_path.lower():
                    results.append({
                        'type': 'directory',
                        'path': dir_path,
                        'purpose': dir_info.get('purpose'),
                        'file_count': dir_info.get('file_count', 0)
                    })
        elif search_type == 'type':
            # æœå°‹ç‰¹å®šé¡å‹æª”æ¡ˆ
            for file_path, file_info in files.items():
                if file_info.get('type') == pattern:
                    results.append({
                        'type': 'file',
                        'path': file_path,
                        'name': file_info.get('name'),
                        'size': file_info.get('size')
                    })
        elif search_type == 'purpose':
            # æœå°‹ç‰¹å®šç”¨é€”çš„ç›®éŒ„
            for dir_path, dir_info in directories.items():
                if dir_info.get('purpose') == pattern:
                    results.append({
                        'type': 'directory',
                        'path': dir_path,
                        'file_count': dir_info.get('file_count', 0),
                        'subdirectories': dir_info.get('subdirectories', [])
                    })
        self.queries_log.append({
            'timestamp': datetime.now().isoformat(),
            'query_type': 'search',
            'pattern': pattern,
            'search_type': search_type,
            'results_count': len(results)
        })
        return results
    def generate_visualization_report(self, filename='phase3_report.md'):
        """ç”Ÿæˆè¦–è¦ºåŒ–å ±å‘Š"""
        print(f"\nğŸ“ ç”Ÿæˆè¦–è¦ºåŒ–å ±å‘Šåˆ° {filename}...")
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("# ç¬¬ä¸‰éšæ®µï¼šè¦–è¦ºåŒ–èˆ‡æŸ¥è©¢ç³»çµ±å ±å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¥æœŸ**: {datetime.now().isoformat()}\n")
            f.write("**éšæ®µ**: Phase 3 - Visualization and Query System\n\n")
            f.write("## ğŸ“Š ç³»çµ±æ¦‚è¦½\n\n")
            f.write(f"- **çŸ¥è­˜åº«æª”æ¡ˆæ•¸**: {len(self.knowledge_base.get('files', {}))}\n")
            f.write(f"- **çŸ¥è­˜åº«ç›®éŒ„æ•¸**: {len(self.knowledge_base.get('directories', {}))}\n")
            f.write(f"- **æŸ¥è©¢æ¬¡æ•¸**: {len(self.queries_log)}\n\n")
            f.write("## ğŸ” æŸ¥è©¢åŠŸèƒ½\n\n")
            f.write("### 1. æª”æ¡ˆä¸Šä¸‹æ–‡æŸ¥è©¢\n\n")
            f.write("```python\n")
            f.write("# æŸ¥è©¢æª”æ¡ˆçš„å®Œæ•´ä¸Šä¸‹æ–‡è³‡è¨Š\n")
            f.write("context = visualizer.query_file_context('path/to/file.py')\n")
            f.write("# è¿”å›: æª”æ¡ˆé¡å‹ã€ç›®éŒ„ç”¨é€”ã€ä¾è³´é—œä¿‚ã€é¢¨éšªç­‰ç´šç­‰\n")
            f.write("```\n\n")
            f.write("### 2. ç›®éŒ„çµæ§‹æŸ¥è©¢\n\n")
            f.write("```python\n")
            f.write("# æŸ¥è©¢ç›®éŒ„çš„å®Œæ•´çµæ§‹\n")
            f.write("structure = visualizer.query_directory_structure('path/to/directory')\n")
            f.write("# è¿”å›: ç›®éŒ„ç”¨é€”ã€å­ç›®éŒ„ã€æª”æ¡ˆåˆ—è¡¨ã€çµ±è¨ˆè³‡è¨Šç­‰\n")
            f.write("```\n\n")
            f.write("### 3. æ¨¡å¼æœå°‹\n\n")
            f.write("```python\n")
            f.write("# æ ¹æ“šåç¨±æœå°‹\n")
            f.write("results = visualizer.search_by_pattern('config', search_type='name')\n")
            f.write("\n")
            f.write("# æ ¹æ“šé¡å‹æœå°‹\n")
            f.write("results = visualizer.search_by_pattern('python', search_type='type')\n")
            f.write("\n")
            f.write("# æ ¹æ“šç”¨é€”æœå°‹\n")
            f.write("results = visualizer.search_by_pattern('configuration', search_type='purpose')\n")
            f.write("```\n\n")
            f.write("## ğŸ“ˆ çµ±è¨ˆè³‡è¨Š\n\n")
            # æª”æ¡ˆé¡å‹çµ±è¨ˆ
            f.write("### æª”æ¡ˆé¡å‹åˆ†ä½ˆ\n\n")
            file_types = defaultdict(int)
            for file_info in self.knowledge_base.get('files', {}).values():
                file_types[file_info.get('type', 'unknown')] += 1
            f.write("| é¡å‹ | æ•¸é‡ | ç™¾åˆ†æ¯” |\n")
            f.write("|------|------|--------|\n")
            total_files = len(self.knowledge_base.get('files', {}))
            for file_type, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True)[:10]:
                percentage = (count / total_files * 100) if total_files > 0 else 0
                f.write(f"| {file_type} | {count} | {percentage:.1f}% |\n")
            f.write("\n")
            # ç›®éŒ„ç”¨é€”çµ±è¨ˆ
            f.write("### ç›®éŒ„ç”¨é€”åˆ†ä½ˆ\n\n")
            dir_purposes = defaultdict(int)
            for dir_info in self.knowledge_base.get('directories', {}).values():
                dir_purposes[dir_info.get('purpose', 'unknown')] += 1
            f.write("| ç”¨é€” | æ•¸é‡ | ç™¾åˆ†æ¯” |\n")
            f.write("|------|------|--------|\n")
            total_dirs = len(self.knowledge_base.get('directories', {}))
            for purpose, count in sorted(dir_purposes.items(), key=lambda x: x[1], reverse=True)[:10]:
                percentage = (count / total_dirs * 100) if total_dirs > 0 else 0
                f.write(f"| {purpose} | {count} | {percentage:.1f}% |\n")
            f.write("\n")
            f.write("## ğŸ”— æª”æ¡ˆé—œä¿‚åœ–ç¤ºä¾‹\n\n")
            f.write("ç³»çµ±èƒ½å¤ è­˜åˆ¥å’Œåˆ†ææª”æ¡ˆä¹‹é–“çš„é—œä¿‚ï¼š\n\n")
            f.write("- **ä¾è³´é—œä¿‚**: å“ªäº›æª”æ¡ˆä¾è³´æ–¼ç•¶å‰æª”æ¡ˆ\n")
            f.write("- **å½±éŸ¿ç¯„åœ**: ä¿®æ”¹ç•¶å‰æª”æ¡ˆæœƒå½±éŸ¿å“ªäº›å…¶ä»–æª”æ¡ˆ\n")
            f.write("- **é¢¨éšªè©•ä¼°**: åŸºæ–¼æª”æ¡ˆé¡å‹å’Œç”¨é€”çš„é¢¨éšªç­‰ç´š\n")
            f.write("- **é—œéµæ€§**: æ¨™è¨˜ç³»çµ±é—œéµæª”æ¡ˆ\n\n")
        print("âœ… è¦–è¦ºåŒ–å ±å‘Šå·²ç”Ÿæˆ")
        return filename
    def print_file_context(self, context: Dict):
        """åˆ—å°æª”æ¡ˆä¸Šä¸‹æ–‡"""
        print(f"\nğŸ“„ æª”æ¡ˆ: {context['file_path']}")
        print(f"   ç‹€æ…‹: {'âœ… å­˜åœ¨' if context['exists'] else 'âŒ ä¸å­˜åœ¨'}")
        if context['exists']:
            print(f"   é¡å‹: {context['type']}")
            print(f"   ç›®éŒ„: {context['directory']}")
            print(f"   ç”¨é€”: {context['purpose']}")
            print(f"   å¤§å°: {context['size']} bytes")
            print(f"   é—œéµæ€§: {'ğŸ”¥ æ˜¯' if context['is_critical'] else 'âŒ å¦'}")
            print(f"   é¢¨éšª: {context['risks']}")
            print(f"   ä¾è³´: {len(context['dependencies'])} å€‹æª”æ¡ˆ")
            print(f"   å½±éŸ¿: {len(context['affected_by'])} å€‹æª”æ¡ˆ")
def main():
    """ä¸»ç¨‹å¼ - æ¼”ç¤ºè¦–è¦ºåŒ–èˆ‡æŸ¥è©¢ç³»çµ±"""
    print("="*60)
    print("ğŸš€ ç¬¬ä¸‰éšæ®µï¼šå»ºç«‹è¦–è¦ºåŒ–èˆ‡æŸ¥è©¢ç³»çµ±")
    print("="*60 + "\n")
    # å‰µå»ºè¦–è¦ºåŒ–å™¨
    visualizer = KnowledgeVisualizer()
    if not visualizer.knowledge_base:
        print("âŒ ç„¡æ³•è¼‰å…¥çŸ¥è­˜åº«ï¼Œè«‹å…ˆåŸ·è¡Œç¬¬ä¸€éšæ®µ")
        return False
    print("âœ… è¦–è¦ºåŒ–ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
    # æ¼”ç¤ºæŸ¥è©¢åŠŸèƒ½
    print("\n" + "="*60)
    print("ğŸ“Š æ¼”ç¤ºæŸ¥è©¢åŠŸèƒ½")
    print("="*60)
    # 1. æŸ¥è©¢æª”æ¡ˆä¸Šä¸‹æ–‡
    context = visualizer.query_file_context('machine-native-ops/README.md')
    visualizer.print_file_context(context)
    # 2. æŸ¥è©¢ç›®éŒ„çµæ§‹
    structure = visualizer.query_directory_structure('machine-native-ops')
    if structure['exists']:
        print(f"\nğŸ“ ç›®éŒ„: {structure['directory_path']}")
        print(f"   ç”¨é€”: {structure['purpose']}")
        print(f"   æª”æ¡ˆæ•¸: {len(structure['files'])}")
        print(f"   ç¸½å¤§å°: {structure['total_size']} bytes")
    # 3. æ¨¡å¼æœå°‹
    results = visualizer.search_by_pattern('config', search_type='name')
    print(f"\nğŸ” æœå°‹ 'config': æ‰¾åˆ° {len(results)} å€‹çµæœ")
    for result in results[:5]:
        icon = "ğŸ“" if result['type'] == 'directory' else "ğŸ“„"
        print(f"   {icon} {result['path']}")
    # 4. ç”Ÿæˆå ±å‘Š
    report_file = visualizer.generate_visualization_report('phase3_report.md')
    print("\n" + "="*60)
    print("âœ… ç¬¬ä¸‰éšæ®µå®Œæˆï¼")
    print("="*60)
    print(f"ğŸ“„ å ±å‘Š: {report_file}")
    print(f"ğŸ“Š åŸ·è¡Œäº† {len(visualizer.queries_log)} æ¬¡æŸ¥è©¢")
    print("="*60)
    return True
if __name__ == '__main__':
    main()