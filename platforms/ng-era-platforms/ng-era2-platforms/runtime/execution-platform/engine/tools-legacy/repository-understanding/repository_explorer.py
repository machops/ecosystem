# @ECO-governed
# @ECO-layer: GL90-99
# @ECO-semantic: archive-tools
# @ECO-audit-trail: ../../engine/gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
# GL Unified Architecture Governance Framework Activated
#
# @ECO-governed
# @ECO-layer: gl-platform.governance
# @ECO-semantic: repository_explorer
# @ECO-audit-trail: ../../engine/gl-platform.governance/GL_SEMANTIC_ANCHOR.json
#
#!/usr/bin/env python3
"""
å„²å­˜åº«æ¢ç´¢å·¥å…· - ç³»çµ±æ€§åœ°æƒæå’Œåˆ†æå„²å­˜åº«çµæ§‹
"""
# MNGA-002: Import organization needs review
import os
import json
from pathlib import Path
from collections import defaultdict
from datetime import datetime
class RepositoryExplorer:
    def __init__(self, root_path='.'):
        self.root_path = Path(root_path)
        self.repository_map = {
            'scan_date': datetime.now().isoformat(),
            'root_path': str(self.root_path.absolute()),
            'directories': {},
            'files': {},
            'structure': {},
            'statistics': {}
        }
    def scan_repository(self):
        """å®Œæ•´æƒæå„²å­˜åº«"""
        print(f"ğŸ” é–‹å§‹æƒæå„²å­˜åº«: {self.root_path}")
        # æƒææ‰€æœ‰ç›®éŒ„å’Œæª”æ¡ˆ
        for root, dirs, files in os.walk(self.root_path):
            root_path = Path(root)
            rel_path = root_path.relative_to(self.root_path)
            # è¨˜éŒ„ç›®éŒ„è³‡è¨Š
            dir_info = {
                'path': str(rel_path),
                'subdirectories': dirs,
                'file_count': len(files),
                'files': files
            }
            self.repository_map['directories'][str(rel_path)] = dir_info
            # è¨˜éŒ„æª”æ¡ˆè³‡è¨Š
            for file in files:
                file_path = root_path / file
                rel_file_path = file_path.relative_to(self.root_path)
                file_info = {
                    'name': file,
                    'path': str(rel_file_path),
                    'size': file_path.stat().st_size if file_path.exists() else 0,
                    'extension': file_path.suffix,
                    'type': self.classify_file_type(file_path.suffix)
                }
                self.repository_map['files'][str(rel_file_path)] = file_info
        # ç”Ÿæˆçµ±è¨ˆè³‡è¨Š
        self.generate_statistics()
        print(f"âœ… æƒæå®Œæˆ: {len(self.repository_map['directories'])} å€‹ç›®éŒ„, {len(self.repository_map['files'])} å€‹æª”æ¡ˆ")
    def classify_file_type(self, extension):
        """åˆ†é¡æª”æ¡ˆé¡å‹"""
        extension = extension.lower()
        type_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.json': 'json',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.md': 'markdown',
            '.txt': 'text',
            '.sh': 'shell',
            '.toml': 'toml',
            '.env': 'environment',
            '.gitignore': 'git',
            '': 'directory'
        }
        return type_map.get(extension, 'unknown')
    def generate_statistics(self):
        """ç”Ÿæˆçµ±è¨ˆè³‡è¨Š"""
        stats = {
            'total_directories': len(self.repository_map['directories']),
            'total_files': len(self.repository_map['files']),
            'file_types': defaultdict(int),
            'largest_files': [],
            'directories_by_depth': defaultdict(int)
        }
        # çµ±è¨ˆæª”æ¡ˆé¡å‹
        for file_path, file_info in self.repository_map['files'].items():
            stats['file_types'][file_info['type']] += 1
        # çµ±è¨ˆç›®éŒ„æ·±åº¦
        for dir_path in self.repository_map['directories'].keys():
            depth = dir_path.count(os.sep)
            stats['directories_by_depth'][depth] += 1
        self.repository_map['statistics'] = dict(stats)
    def analyze_structure(self):
        """åˆ†æå„²å­˜åº«çµæ§‹"""
        print("ğŸ“Š åˆ†æå„²å­˜åº«çµæ§‹...")
        # è­˜åˆ¥é—œéµç›®éŒ„
        key_directories = self.identify_key_directories()
        self.repository_map['structure']['key_directories'] = key_directories
        # è­˜åˆ¥é…ç½®æª”æ¡ˆ
        config_files = self.identify_config_files()
        self.repository_map['structure']['config_files'] = config_files
        # è­˜åˆ¥æ–‡ä»¶æª”æ¡ˆ
        doc_files = self.identify_documentation_files()
        self.repository_map['structure']['documentation_files'] = doc_files
    def identify_key_directories(self):
        """è­˜åˆ¥é—œéµç›®éŒ„"""
        key_dirs = {}
        for dir_path, dir_info in self.repository_map['directories'].items():
            path_parts = dir_path.split(os.sep)
            # æ ¹æ“šç›®éŒ„åç¨±è­˜åˆ¥ç”¨é€”
            for part in path_parts:
                if part.lower() in ['src', 'source', 'lib', 'library']:
                    key_dirs[dir_path] = 'source_code'
                elif part.lower() in ['docs', 'doc', 'documentation']:
                    key_dirs[dir_path] = 'documentation'
                elif part.lower() in ['config', 'configuration', 'etc']:
                    key_dirs[dir_path] = 'configuration'
                elif part.lower() in ['test', 'tests', 'spec']:
                    key_dirs[dir_path] = 'testing'
                elif part.lower() in ['bin', 'sbin', 'scripts']:
                    key_dirs[dir_path] = 'scripts'
                elif part.lower() in ['workspace', 'work']:
                    key_dirs[dir_path] = 'workspace'
        return key_dirs
    def identify_config_files(self):
        """è­˜åˆ¥é…ç½®æª”æ¡ˆ"""
        config_files = []
        for file_path, file_info in self.repository_map['files'].items():
            if file_info['type'] in ['yaml', 'json', 'toml', 'environment']:
                config_files.append({
                    'path': file_path,
                    'type': file_info['type'],
                    'size': file_info['size']
                })
        return config_files
    def identify_documentation_files(self):
        """è­˜åˆ¥æ–‡ä»¶æª”æ¡ˆ"""
        doc_files = []
        for file_path, file_info in self.repository_map['files'].items():
            if file_info['type'] == 'markdown' or file_path.lower().endswith('readme'):
                doc_files.append({
                    'path': file_path,
                    'size': file_info['size']
                })
        return doc_files
    def generate_report(self, output_file='repository_map.json'):
        """ç”Ÿæˆå ±å‘Š"""
        print(f"ğŸ“ ç”Ÿæˆå ±å‘Š: {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.repository_map, f, indent=2, ensure_ascii=False)
        print(f"âœ… å ±å‘Šå·²ä¿å­˜: {output_file}")
    def print_summary(self):
        """åˆ—å°æ‘˜è¦"""
        stats = self.repository_map['statistics']
        print("\n" + "="*50)
        print("ğŸ“Š å„²å­˜åº«æ‘˜è¦")
        print("="*50)
        print(f"ç¸½ç›®éŒ„æ•¸: {stats['total_directories']}")
        print(f"ç¸½æª”æ¡ˆæ•¸: {stats['total_files']}")
        print("\næª”æ¡ˆé¡å‹åˆ†ä½ˆ:")
        for file_type, count in sorted(stats['file_types'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {file_type}: {count}")
        print("="*50 + "\n")
def main():
    """ä¸»ç¨‹å¼"""
    # å‰µå»ºæ¢ç´¢å™¨
    explorer = RepositoryExplorer()
    # åŸ·è¡Œæƒæ
    explorer.scan_repository()
    # åˆ†æçµæ§‹
    explorer.analyze_structure()
    # åˆ—å°æ‘˜è¦
    explorer.print_summary()
    # ç”Ÿæˆå ±å‘Š
    explorer.generate_report('repository_map.json')
    # ç”Ÿæˆäººé¡å¯è®€å ±å‘Š
    generate_human_readable_report(explorer)
def generate_human_readable_report(explorer):
    """ç”Ÿæˆäººé¡å¯è®€çš„å ±å‘Š"""
    report_file = 'repository_structure_report.md'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# å„²å­˜åº«çµæ§‹å ±å‘Š\n\n")
        f.write(f"**æƒææ—¥æœŸ**: {explorer.repository_map['scan_date']}\n")
        f.write(f"**æ ¹è·¯å¾‘**: {explorer.repository_map['root_path']}\n\n")
        # çµ±è¨ˆè³‡è¨Š
        stats = explorer.repository_map['statistics']
        f.write("## çµ±è¨ˆè³‡è¨Š\n\n")
        f.write(f"- **ç¸½ç›®éŒ„æ•¸**: {stats['total_directories']}\n")
        f.write(f"- **ç¸½æª”æ¡ˆæ•¸**: {stats['total_files']}\n\n")
        f.write("### æª”æ¡ˆé¡å‹åˆ†ä½ˆ\n\n")
        f.write("| é¡å‹ | æ•¸é‡ |\n")
        f.write("|------|------|\n")
        for file_type, count in sorted(stats['file_types'].items(), key=lambda x: x[1], reverse=True):
            f.write(f"| {file_type} | {count} |\n")
        f.write("\n")
        # é—œéµç›®éŒ„
        f.write("## é—œéµç›®éŒ„\n\n")
        key_dirs = explorer.repository_map['structure'].get('key_directories', {})
        for dir_path, purpose in key_dirs.items():
            f.write(f"- **{dir_path}**: {purpose}\n")
        f.write("\n")
        # é…ç½®æª”æ¡ˆ
        f.write("## é…ç½®æª”æ¡ˆ\n\n")
        config_files = explorer.repository_map['structure'].get('config_files', [])
        for config in config_files:
            f.write(f"- **{config['path']}** ({config['type']})\n")
        f.write("\n")
        # æ–‡ä»¶æª”æ¡ˆ
        f.write("## æ–‡ä»¶æª”æ¡ˆ\n\n")
        doc_files = explorer.repository_map['structure'].get('documentation_files', [])
        for doc in doc_files:
            f.write(f"- **{doc['path']}**\n")
        f.write("\n")
    print(f"âœ… äººé¡å¯è®€å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
if __name__ == '__main__':
    main()