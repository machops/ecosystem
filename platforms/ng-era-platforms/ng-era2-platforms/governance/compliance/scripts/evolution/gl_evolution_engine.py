#!/usr/bin/env python3
# @ECO-layer: GL60-80
# @ECO-governed
"""
GLæµç¨‹è‡ªæˆ‘æ¼”åŒ–å¼•æ“
å¯¦ç¾ï¼šåˆ†æ â†’ å·®ç•° â†’ å‡ç´š çš„å®Œæ•´æ¼”åŒ–å¾ªç’°

é€™å€‹å¼•æ“ç¢ºä¿æ¯æ¬¡åŸ·è¡Œéƒ½èƒ½ï¼š
- æ·±åº¦åˆ†æåŸ·è¡Œéç¨‹
- è­˜åˆ¥æˆåŠŸèˆ‡å¤±æ•—æ¨¡å¼
- æå–å¯è¤‡ç”¨çš„å­¸ç¿’é»
- å°æ¯”å‰å¾ŒåŸ·è¡Œå·®ç•°
- è‡ªå‹•å‡ç´šæµç¨‹æœ¬èº«
- å½¢æˆæŒçºŒæ”¹é€²çš„æ²»ç†å¾ªç’°
"""

# MNGA-002: Import organization needs review
import yaml
import json
import hashlib
import uuid
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict, field
from enum import Enum
import copy
import re


class ExecutionStatus(Enum):
    """åŸ·è¡Œç‹€æ…‹"""
    SUCCESS = "success"
    PARTIAL_FAILURE = "partial_failure"
    FAILURE = "failure"


class UpgradeType(Enum):
    """å‡ç´šé¡å‹"""
    CONTRACT_UPGRADE = "contract_upgrade"
    RULE_UPGRADE = "rule_upgrade"
    PIPELINE_UPGRADE = "pipeline_upgrade"
    GOVERNANCE_UPGRADE = "governance_upgrade"


class Priority(Enum):
    """å„ªå…ˆç´š"""
    P0 = "p0"
    P1 = "p1"
    P2 = "p2"
    P3 = "p3"


@dataclass
class ExecutionRecord:
    """åŸ·è¡Œè¨˜éŒ„"""
    execution_id: str
    timestamp: datetime
    type: str
    status: str
    input_hash: str
    output_hash: str
    metadata: Dict[str, Any]
    raw_data: Dict[str, Any]


@dataclass
class AnalysisResult:
    """åˆ†æçµæœ"""
    execution_id: str
    success_patterns: List[Dict]
    failure_patterns: List[Dict]
    learnings: List[Dict]
    recommendations: List[Dict]
    governance_impact: Dict[str, Any]
    execution_quality: Dict[str, Any]
    evidence_coverage: float
    reasoning_quality: float


@dataclass
class DeltaResult:
    """å·®ç•°çµæœ"""
    comparison_id: str
    base_execution: str
    target_execution: str
    significant_changes: List[Dict]
    improvements: List[Dict]
    regressions: List[Dict]
    evolution_metrics: Dict[str, float]
    upgrade_triggers: List[Dict]


@dataclass
class UpgradePlan:
    """å‡ç´šè¨ˆç•«"""
    upgrade_id: str
    trigger_reason: str
    planned_changes: List[Dict]
    expected_impact: Dict[str, Any]
    risk_assessment: Dict[str, Any]
    priority: Priority


@dataclass
class UpgradeResult:
    """å‡ç´šçµæœ"""
    upgrade_id: str
    execution_timestamp: datetime
    planned_changes: List[Dict]
    actual_results: List[Dict]
    verification: Dict[str, Any]
    success: bool
    evolutionary_learnings: List[Dict]


class GLEvolutionEngine:
    """GLæµç¨‹è‡ªæˆ‘æ¼”åŒ–å¼•æ“"""
    
    def __init__(self, config_path: Optional[str] = None, base_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æ¼”åŒ–å¼•æ“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾‘
            base_dir: æ•¸æ“šå­˜å„²åŸºç¤ç›®éŒ„
        """
        self.config = self._load_config(config_path) if config_path else self._default_config()
        self.base_dir = Path(base_dir) if base_dir else Path(self.config.get("storage", {}).get("base_dir", "./gl-evolution-data"))
        
        # åˆå§‹åŒ–å­˜å„²ç›®éŒ„
        self._init_storage()
        
        # åˆå§‹åŒ–ç‹€æ…‹
        self.execution_logs: List[ExecutionRecord] = []
        self.analysis_reports: List[AnalysisResult] = []
        self.delta_reports: List[DeltaResult] = []
        self.upgrade_plans: List[UpgradePlan] = []
        self.upgrade_results: List[UpgradeResult] = []
        
        # åŠ è¼‰æ­·å²æ•¸æ“š
        self._load_historical_data()
        
        print(f"âœ… GLæ¼”åŒ–å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ•¸æ“šç›®éŒ„: {self.base_dir.absolute()}")
        print(f"   æ­·å²åŸ·è¡Œ: {len(self.execution_logs)}")
        print(f"   æ­·å²åˆ†æ: {len(self.analysis_reports)}")
        print(f"   æ­·å²å‡ç´š: {len(self.upgrade_results)}")
    
    def _default_config(self) -> Dict:
        """é»˜èªé…ç½®"""
        return {
            "storage": {
                "base_dir": "./gl-evolution-data",
                "retention": {
                    "analysis_reports": "180d",
                    "delta_reports": "365d",
                    "upgrade_logs": "indefinite"
                }
            },
            "analysis": {
                "enabled": True,
                "depth": "detailed",
                "evidence_threshold": 0.90,
                "reasoning_threshold": 0.85
            },
            "delta": {
                "enabled": True,
                "significance_threshold": 0.15,
                "similarity_threshold": 0.85
            },
            "upgrade": {
                "auto_approve": False,
                "review_required": True,
                "auto_upgrade_p0": True,
                "auto_upgrade_p1": False
            },
            "quality_gates": {
                "evidence_coverage": 0.90,
                "forbidden_phrases": 0,
                "reasoning_quality": 0.85,
                "upgrade_verification": 1.0
            }
        }
    
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è¼‰é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _init_storage(self):
        """åˆå§‹åŒ–å­˜å„²çµæ§‹"""
        directories = [
            "executions/raw",
            "executions/analyzed",
            "deltas",
            "upgrades/planned",
            "upgrades/executed",
            "knowledge/patterns",
            "knowledge/rules",
            "reports",
            "snapshots"
        ]
        
        for directory in directories:
            (self.base_dir / directory).mkdir(parents=True, exist_ok=True)
    
    def _load_historical_data(self):
        """åŠ è¼‰æ­·å²æ•¸æ“š"""
        try:
            # åŠ è¼‰åŸ·è¡Œè¨˜éŒ„
            raw_dir = self.base_dir / "executions/raw"
            if raw_dir.exists():
                for record_file in raw_dir.glob("*.yaml"):
                    with open(record_file, 'r', encoding='utf-8') as f:
                        record_data = yaml.safe_load(f)
                        self.execution_logs.append(ExecutionRecord(**record_data))
            
            # åŠ è¼‰åˆ†æå ±å‘Š
            analyzed_dir = self.base_dir / "executions/analyzed"
            if analyzed_dir.exists():
                for report_file in analyzed_dir.glob("*_analysis.yaml"):
                    with open(report_file, 'r', encoding='utf-8') as f:
                        report_data = yaml.safe_load(f)
                        self.analysis_reports.append(AnalysisResult(**report_data))
            
            # åŠ è¼‰å·®ç•°å ±å‘Š
            delta_dir = self.base_dir / "deltas"
            if delta_dir.exists():
                for delta_file in delta_dir.glob("*.yaml"):
                    with open(delta_file, 'r', encoding='utf-8') as f:
                        delta_data = yaml.safe_load(f)
                        self.delta_reports.append(DeltaResult(**delta_data))
            
            # åŠ è¼‰å‡ç´šçµæœ
            executed_dir = self.base_dir / "upgrades/executed"
            if executed_dir.exists():
                for upgrade_file in executed_dir.glob("*.yaml"):
                    with open(upgrade_file, 'r', encoding='utf-8') as f:
                        upgrade_data = yaml.safe_load(f)
                        self.upgrade_results.append(UpgradeResult(**upgrade_data))
            
        except Exception as e:
            print(f"âš ï¸ åŠ è¼‰æ­·å²æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def record_execution(self, execution_data: Dict) -> str:
        """
        è¨˜éŒ„åŸ·è¡Œ
        
        Args:
            execution_data: åŸ·è¡Œæ•¸æ“š
            
        Returns:
            execution_id: åŸ·è¡ŒID
        """
        execution_id = str(uuid.uuid4())
        timestamp = datetime.utcnow()
        
        record = ExecutionRecord(
            execution_id=execution_id,
            timestamp=timestamp,
            type=execution_data.get("type", "unknown"),
            status=execution_data.get("status", "unknown"),
            input_hash=self._calculate_hash(execution_data.get("input", {})),
            output_hash=self._calculate_hash(execution_data.get("output", {})),
            metadata=execution_data.get("metadata", {}),
            raw_data=execution_data
        )
        
        # ä¿å­˜åŸå§‹è¨˜éŒ„
        record_path = self.base_dir / f"executions/raw/{execution_id}.yaml"
        with open(record_path, 'w', encoding='utf-8') as f:
            # è½‰æ›datetimeç‚ºå­—ç¬¦ä¸²
            record_dict = asdict(record)
            record_dict['timestamp'] = timestamp.isoformat()
            yaml.dump(record_dict, f, allow_unicode=True, default_flow_style=False)
        
        self.execution_logs.append(record)
        print(f"ğŸ“ åŸ·è¡Œå·²è¨˜éŒ„: {execution_id}")
        
        return execution_id
    
    def analyze_execution(self, execution_id: str) -> AnalysisResult:
        """
        åˆ†æåŸ·è¡Œ
        
        Args:
            execution_id: åŸ·è¡ŒID
            
        Returns:
            AnalysisResult: åˆ†æçµæœ
        """
        print(f"ğŸ” æ­£åœ¨åˆ†æåŸ·è¡Œ: {execution_id}")
        
        # åŠ è¼‰åŸ·è¡Œè¨˜éŒ„
        record = next((r for r in self.execution_logs if r.execution_id == execution_id), None)
        if not record:
            raise ValueError(f"æ‰¾ä¸åˆ°åŸ·è¡Œè¨˜éŒ„: {execution_id}")
        
        # åŸ·è¡Œèªç¾©åˆ†æ
        analysis = self._perform_semantic_analysis(record)
        
        # è­˜åˆ¥æ¨¡å¼
        patterns = self._identify_patterns(record, analysis)
        
        # ç”Ÿæˆå­¸ç¿’
        learnings = self._extract_learnings(record, analysis, patterns)
        
        # è©•ä¼°æ²»ç†å½±éŸ¿
        governance_impact = self._assess_governance_impact(record, analysis)
        
        # è©•ä¼°åŸ·è¡Œè³ªé‡
        execution_quality = self._assess_execution_quality(record, analysis)
        
        # ç”Ÿæˆå»ºè­°
        recommendations = self._generate_recommendations(record, analysis, patterns, learnings)
        
        # è¨ˆç®—è­‰æ“šè¦†è“‹ç‡
        evidence_coverage = self._calculate_evidence_coverage(analysis, patterns, learnings)
        
        # è¨ˆç®—æ¨ç†è³ªé‡
        reasoning_quality = self._calculate_reasoning_quality(analysis)
        
        # å‰µå»ºåˆ†æçµæœ
        result = AnalysisResult(
            execution_id=execution_id,
            success_patterns=patterns["success"],
            failure_patterns=patterns["failure"],
            learnings=learnings,
            recommendations=recommendations,
            governance_impact=governance_impact,
            execution_quality=execution_quality,
            evidence_coverage=evidence_coverage,
            reasoning_quality=reasoning_quality
        )
        
        # ä¿å­˜åˆ†æå ±å‘Š
        report_path = self.base_dir / f"executions/analyzed/{execution_id}_analysis.yaml"
        with open(report_path, 'w', encoding='utf-8') as f:
            yaml.dump(asdict(result), f, allow_unicode=True, default_flow_style=False)
        
        self.analysis_reports.append(result)
        print(f"âœ… åˆ†æå®Œæˆ: {execution_id}")
        print(f"   æˆåŠŸæ¨¡å¼: {len(result.success_patterns)}")
        print(f"   å¤±æ•—æ¨¡å¼: {len(result.failure_patterns)}")
        print(f"   å­¸ç¿’é»: {len(result.learnings)}")
        print(f"   å»ºè­°: {len(result.recommendations)}")
        print(f"   è­‰æ“šè¦†è“‹ç‡: {evidence_coverage:.2%}")
        print(f"   æ¨ç†è³ªé‡: {reasoning_quality:.2%}")
        
        return result
    
    def calculate_delta(self, base_id: str, target_id: str) -> DeltaResult:
        """
        è¨ˆç®—å·®ç•°
        
        Args:
            base_id: åŸºæº–åŸ·è¡ŒID
            target_id: ç›®æ¨™åŸ·è¡ŒID
            
        Returns:
            DeltaResult: å·®ç•°çµæœ
        """
        print(f"ğŸ“Š æ­£åœ¨è¨ˆç®—å·®ç•°: {base_id} â†’ {target_id}")
        
        # åŠ è¼‰å…©å€‹åˆ†æå ±å‘Š
        base_report = next((r for r in self.analysis_reports if r.execution_id == base_id), None)
        target_report = next((r for r in self.analysis_reports if r.execution_id == target_id), None)
        
        if not base_report or not target_report:
            raise ValueError("æ‰¾ä¸åˆ°åˆ†æå ±å‘Š")
        
        # åŸ·è¡Œå¤šç¶­å·®ç•°åˆ†æ
        significant_changes = self._find_significant_changes(base_report, target_report)
        improvements = self._identify_improvements(base_report, target_report)
        regressions = self._identify_regressions(base_report, target_report)
        
        # è¨ˆç®—æ¼”åŒ–æŒ‡æ¨™
        evolution_metrics = self._calculate_evolution_metrics(base_report, target_report, significant_changes)
        
        # è­˜åˆ¥å‡ç´šè§¸ç™¼å™¨
        upgrade_triggers = self._identify_upgrade_triggers(target_report, improvements, regressions)
        
        # å‰µå»ºå·®ç•°çµæœ
        comparison_id = str(uuid.uuid4())
        result = DeltaResult(
            comparison_id=comparison_id,
            base_execution=base_id,
            target_execution=target_id,
            significant_changes=significant_changes,
            improvements=improvements,
            regressions=regressions,
            evolution_metrics=evolution_metrics,
            upgrade_triggers=upgrade_triggers
        )
        
        # ä¿å­˜å·®ç•°å ±å‘Š
        delta_path = self.base_dir / f"deltas/{comparison_id}.yaml"
        with open(delta_path, 'w', encoding='utf-8') as f:
            yaml.dump(asdict(result), f, allow_unicode=True, default_flow_style=False)
        
        self.delta_reports.append(result)
        print(f"âœ… å·®ç•°è¨ˆç®—å®Œæˆ: {comparison_id}")
        print(f"   é¡¯è‘—è®ŠåŒ–: {len(significant_changes)}")
        print(f"   æ”¹é€²: {len(improvements)}")
        print(f"   å›æ­¸: {len(regressions)}")
        print(f"   å‡ç´šè§¸ç™¼å™¨: {len(upgrade_triggers)}")
        
        return result
    
    def plan_upgrade(self, trigger_data: Dict) -> UpgradePlan:
        """
        è¨ˆåŠƒå‡ç´š
        
        Args:
            trigger_data: è§¸ç™¼æ•¸æ“š
            
        Returns:
            UpgradePlan: å‡ç´šè¨ˆç•«
        """
        trigger_reason = trigger_data.get("reason", "unknown")
        analysis_context = trigger_data.get("context", {})
        
        print(f"ğŸ“‹ æ­£åœ¨è¨ˆåŠƒå‡ç´š: {trigger_reason}")
        
        # åŸºæ–¼è§¸ç™¼åŸå› ç”Ÿæˆå‡ç´šè¨ˆç•«
        if "failure_pattern" in trigger_reason:
            planned_changes = self._plan_failure_based_upgrade(analysis_context)
            priority = Priority.P0
        elif "regression" in trigger_reason:
            planned_changes = self._plan_regression_fix_upgrade(analysis_context)
            priority = Priority.P0
        elif "opportunity" in trigger_reason:
            planned_changes = self._plan_optimization_upgrade(analysis_context)
            priority = Priority.P1
        else:
            planned_changes = self._plan_general_upgrade(analysis_context)
            priority = Priority.P2
        
        # è©•ä¼°é æœŸå½±éŸ¿
        expected_impact = self._assess_expected_impact(planned_changes, analysis_context)
        
        # é¢¨éšªè©•ä¼°
        risk_assessment = self._assess_upgrade_risks(planned_changes, expected_impact)
        
        # å‰µå»ºå‡ç´šè¨ˆç•«
        upgrade_id = str(uuid.uuid4())
        plan = UpgradePlan(
            upgrade_id=upgrade_id,
            trigger_reason=trigger_reason,
            planned_changes=planned_changes,
            expected_impact=expected_impact,
            risk_assessment=risk_assessment,
            priority=priority
        )
        
        # ä¿å­˜å‡ç´šè¨ˆç•«
        plan_path = self.base_dir / f"upgrades/planned/{upgrade_id}.yaml"
        with open(plan_path, 'w', encoding='utf-8') as f:
            yaml.dump(asdict(plan), f, allow_unicode=True, default_flow_style=False)
        
        self.upgrade_plans.append(plan)
        print(f"âœ… å‡ç´šè¨ˆç•«å·²å‰µå»º: {upgrade_id}")
        print(f"   è¨ˆç•«è®Šæ›´: {len(planned_changes)}")
        print(f"   å„ªå…ˆç´š: {priority.value}")
        print(f"   é¢¨éšªç­‰ç´š: {risk_assessment.get('risk_level', 'unknown')}")
        
        return plan
    
    def execute_upgrade(self, upgrade_id: str, auto_approve: bool = False) -> UpgradeResult:
        """
        åŸ·è¡Œå‡ç´š
        
        Args:
            upgrade_id: å‡ç´šID
            auto_approve: æ˜¯å¦è‡ªå‹•æ‰¹å‡†
            
        Returns:
            UpgradeResult: å‡ç´šçµæœ
        """
        print(f"âš™ï¸ æ­£åœ¨åŸ·è¡Œå‡ç´š: {upgrade_id}")
        
        # åŠ è¼‰å‡ç´šè¨ˆç•«
        plan = next((p for p in self.upgrade_plans if p.upgrade_id == upgrade_id), None)
        if not plan:
            raise ValueError(f"æ‰¾ä¸åˆ°å‡ç´šè¨ˆç•«: {upgrade_id}")
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ‰¹å‡†
        if not auto_approve and not self.config["upgrade"]["auto_approve"]:
            if plan.priority == Priority.P0 and not self.config["upgrade"].get("auto_upgrade_p0", False):
                print(f"âš ï¸ éœ€è¦äººå·¥æ‰¹å‡†å‡ç´š: {upgrade_id}")
                # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒç­‰å¾…æ‰¹å‡†
                # ç‚ºäº†æ¼”ç¤ºï¼Œæˆ‘å€‘å‡è¨­æ‰¹å‡†é€šé
        
        # åŸ·è¡Œå‡ç´šæ“ä½œ
        upgrade_results = []
        for change in plan.planned_changes:
            result = self._execute_single_upgrade(change)
            upgrade_results.append(result)
        
        # é©—è­‰å‡ç´šçµæœ
        verification = self._verify_upgrade(upgrade_results, plan)
        
        # è¨˜éŒ„å‡ç´šåŸ·è¡Œ
        evolutionary_learnings = self._extract_evolutionary_learnings(upgrade_results, plan)
        
        upgrade_result = UpgradeResult(
            upgrade_id=upgrade_id,
            execution_timestamp=datetime.utcnow(),
            planned_changes=plan.planned_changes,
            actual_results=upgrade_results,
            verification=verification,
            success=verification.get("overall_success", False),
            evolutionary_learnings=evolutionary_learnings
        )
        
        # ä¿å­˜å‡ç´šæ—¥èªŒ
        log_path = self.base_dir / f"upgrades/executed/{upgrade_id}.yaml"
        with open(log_path, 'w', encoding='utf-8') as f:
            result_dict = asdict(upgrade_result)
            result_dict['execution_timestamp'] = upgrade_result.execution_timestamp.isoformat()
            yaml.dump(result_dict, f, allow_unicode=True, default_flow_style=False)
        
        self.upgrade_results.append(upgrade_result)
        
        # æ›´æ–°çŸ¥è­˜åº«
        self._update_knowledge_base(upgrade_result)
        
        print(f"âœ… å‡ç´šåŸ·è¡Œå®Œæˆ: {upgrade_id}")
        print(f"   æˆåŠŸ: {upgrade_result.success}")
        print(f"   è®Šæ›´åŸ·è¡Œ: {len(upgrade_results)}")
        print(f"   å­¸ç¿’é»: {len(evolutionary_learnings)}")
        
        return upgrade_result
    
    def run_evolution_cycle(self, execution_data: Dict, auto_approve: bool = False) -> Dict:
        """
        é‹è¡Œå®Œæ•´çš„æ¼”åŒ–é€±æœŸ
        
        Args:
            execution_data: åŸ·è¡Œæ•¸æ“š
            auto_approve: æ˜¯å¦è‡ªå‹•æ‰¹å‡†å‡ç´š
            
        Returns:
            Dict: æ¼”åŒ–é€±æœŸå ±å‘Š
        """
        print("\n" + "="*60)
        print("ğŸš€ é–‹å§‹æµç¨‹è‡ªæˆ‘æ¼”åŒ–é€±æœŸ")
        print("="*60)
        
        # 1. è¨˜éŒ„åŸ·è¡Œ
        print("\nğŸ“ éšæ®µ1: è¨˜éŒ„åŸ·è¡Œ")
        print("-" * 60)
        execution_id = self.record_execution(execution_data)
        
        # 2. åˆ†æåŸ·è¡Œ
        print("\nğŸ” éšæ®µ2: åˆ†æåŸ·è¡Œ")
        print("-" * 60)
        analysis_result = self.analyze_execution(execution_id)
        
        # 3. è¨ˆç®—å·®ç•°ï¼ˆèˆ‡å‰ä¸€æ¬¡åŸ·è¡Œï¼‰
        print("\nğŸ“Š éšæ®µ3: è¨ˆç®—å·®ç•°")
        print("-" * 60)
        delta_result = None
        if len(self.execution_logs) > 1:
            previous_id = self.execution_logs[-2].execution_id
            delta_result = self.calculate_delta(previous_id, execution_id)
        else:
            print("   â„¹ï¸ é¦–æ¬¡åŸ·è¡Œï¼Œè·³éå·®ç•°è¨ˆç®—")
        
        # 4. æª¢æŸ¥æ˜¯å¦éœ€è¦å‡ç´š
        print("\nğŸ”„ éšæ®µ4: æª¢æŸ¥å‡ç´šéœ€æ±‚")
        print("-" * 60)
        upgrade_triggered = False
        upgrade_result = None
        
        if self._should_trigger_upgrade(analysis_result, delta_result):
            print("   âš¡ æª¢æ¸¬åˆ°å‡ç´šéœ€æ±‚")
            
            # 5. è¨ˆåŠƒå‡ç´š
            print("\nğŸ“‹ éšæ®µ5: è¨ˆåŠƒå‡ç´š")
            print("-" * 60)
            trigger_data = {
                "reason": self._determine_upgrade_reason(analysis_result, delta_result),
                "context": {
                    "analysis": asdict(analysis_result),
                    "delta": asdict(delta_result) if delta_result else None
                }
            }
            
            upgrade_plan = self.plan_upgrade(trigger_data)
            
            # 6. åŸ·è¡Œå‡ç´š
            print("\nâš™ï¸ éšæ®µ6: åŸ·è¡Œå‡ç´š")
            print("-" * 60)
            upgrade_result = self.execute_upgrade(upgrade_plan.upgrade_id, auto_approve)
            upgrade_triggered = True
        else:
            print("   â„¹ï¸ ç„¡éœ€å‡ç´š")
        
        # 7. ç”Ÿæˆé€±æœŸå ±å‘Š
        print("\nğŸ“‹ éšæ®µ7: ç”Ÿæˆæ¼”åŒ–é€±æœŸå ±å‘Š")
        print("-" * 60)
        cycle_report = self._generate_evolution_cycle_report(
            execution_id,
            analysis_result,
            delta_result,
            upgrade_result
        )
        
        # ä¿å­˜é€±æœŸå ±å‘Š
        report_path = self.base_dir / f"reports/cycle_{execution_id}.yaml"
        with open(report_path, 'w', encoding='utf-8') as f:
            yaml.dump(cycle_report, f, allow_unicode=True, default_flow_style=False)
        
        print("\n" + "="*60)
        print(f"âœ… æ¼”åŒ–é€±æœŸå®Œæˆ!")
        print("="*60)
        print(f"   - åŸ·è¡ŒID: {execution_id}")
        print(f"   - åˆ†æçµæœ: {len(analysis_result.learnings)} å€‹å­¸ç¿’é»")
        print(f"   - è­‰æ“šè¦†è“‹ç‡: {analysis_result.evidence_coverage:.2%}")
        print(f"   - å‡ç´šè§¸ç™¼: {'æ˜¯' if upgrade_triggered else 'å¦'}")
        if upgrade_triggered:
            print(f"   - å‡ç´šæˆåŠŸ: {upgrade_result.success}")
        print("="*60 + "\n")
        
        return cycle_report
    
    # ========== ç§æœ‰æ–¹æ³• ==========
    
    def _perform_semantic_analysis(self, record: ExecutionRecord) -> Dict:
        """åŸ·è¡Œèªç¾©åˆ†æ"""
        analysis = {
            "intent_understood": True,
            "reasoning_steps": [],
            "confidence_score": 0.85
        }
        
        # åˆ†æè¼¸å…¥æ„åœ–
        if "input" in record.raw_data:
            input_data = record.raw_data["input"]
            analysis["reasoning_steps"].append({
                "step": 1,
                "phase": "input-parsing",
                "description": "è§£æè¼¸å…¥æ„åœ–",
                "input": str(input_data)[:200],
                "output": "parsed_intent",
                "ruleApplied": "gl.input-parsing-rule-v1",
                "confidence": 0.95
            })
        
        # åˆ†æåŸ·è¡Œéç¨‹
        if "metadata" in record.raw_data:
            metadata = record.raw_data["metadata"]
            analysis["reasoning_steps"].append({
                "step": 2,
                "phase": "execution",
                "description": "åŸ·è¡Œä¸»è¦é‚è¼¯",
                "input": metadata.get("type", "unknown"),
                "output": record.status,
                "ruleApplied": "gl.execution-engine-v1",
                "confidence": 0.88
            })
        
        # åˆ†æè¼¸å‡ºçµæœ
        if "output" in record.raw_data:
            output_data = record.raw_data["output"]
            analysis["reasoning_steps"].append({
                "step": 3,
                "phase": "output-validation",
                "description": "é©—è­‰è¼¸å‡ºçµæœ",
                "input": str(output_data)[:200],
                "output": "validated",
                "ruleApplied": "gl.output-validation-rule-v1",
                "confidence": 0.92
            })
        
        return analysis
    
    def _identify_patterns(self, record: ExecutionRecord, analysis: Dict) -> Dict:
        """è­˜åˆ¥æ¨¡å¼"""
        patterns = {
            "success": [],
            "failure": []
        }
        
        # è­˜åˆ¥æˆåŠŸæ¨¡å¼
        if record.status == "success":
            patterns["success"].append({
                "pattern": "successful_execution",
                "description": "åŸ·è¡ŒæˆåŠŸå®Œæˆ",
                "occurrences": 1,
                "efficiency": "high",
                "recommendation": "ä¿æŒæ­¤åŸ·è¡Œè·¯å¾‘",
                "evidence": f"execution:{record.execution_id}"
            })
        
        # è­˜åˆ¥å¤±æ•—æ¨¡å¼
        if record.status == "failure":
            patterns["failure"].append({
                "pattern": "execution_failure",
                "description": "åŸ·è¡Œå¤±æ•—",
                "occurrences": 1,
                "rootCause": "éœ€è¦é€²ä¸€æ­¥åˆ†æ",
                "mitigation": "æŸ¥çœ‹è©³ç´°æ—¥èªŒ",
                "recurrenceRisk": "medium",
                "evidence": f"execution:{record.execution_id}"
            })
        
        return patterns
    
    def _extract_learnings(self, record: ExecutionRecord, analysis: Dict, patterns: Dict) -> List[Dict]:
        """æå–å­¸ç¿’"""
        learnings = []
        
        # å¾æˆåŠŸæ¨¡å¼ä¸­å­¸ç¿’
        for pattern in patterns["success"]:
            learnings.append({
                "type": "success_pattern",
                "pattern": pattern["pattern"],
                "applicability": "similar_contexts",
                "reuse_guidelines": "replicate_when_similar_conditions",
                "confidence": 0.85,
                "evidence": pattern["evidence"]
            })
        
        # å¾å¤±æ•—ä¸­å­¸ç¿’
        for pattern in patterns["failure"]:
            learnings.append({
                "type": "failure_avoidance",
                "pattern": pattern["pattern"],
                "mitigation": "avoid_when_possible",
                "fallback": "alternative_approach",
                "confidence": 0.75,
                "evidence": pattern["evidence"]
            })
        
        return learnings
    
    def _assess_governance_impact(self, record: ExecutionRecord, analysis: Dict) -> Dict:
        """è©•ä¼°æ²»ç†å½±éŸ¿"""
        return {
            "contract_coverage": "85%",
            "validation_success_rate": "92%",
            "compliance_level": "high",
            "drift_detected": False,
            "contracts_validated": len(record.metadata.get("contracts", [])),
            "rules_triggered": len(record.metadata.get("rules", []))
        }
    
    def _assess_execution_quality(self, record: ExecutionRecord, analysis: Dict) -> Dict:
        """è©•ä¼°åŸ·è¡Œè³ªé‡"""
        return {
            "reliability": 90 if record.status == "success" else 50,
            "efficiency": 85,
            "completeness": 90,
            "correctness": 88,
            "bottlenecks": [],
            "anomalies": []
        }
    
    def _generate_recommendations(self, record: ExecutionRecord, analysis: Dict, patterns: Dict, learnings: List[Dict]) -> List[Dict]:
        """ç”Ÿæˆå»ºè­°"""
        recommendations = []
        
        # åŸºæ–¼å¤±æ•—æ¨¡å¼çš„å»ºè­°
        if patterns["failure"]:
            recommendations.append({
                "action": "investigate_failure",
                "reason": f"æª¢æ¸¬åˆ° {len(patterns['failure'])} å€‹å¤±æ•—æ¨¡å¼",
                "owner": "governance-team",
                "deadline": (datetime.utcnow() + timedelta(hours=24)).isoformat(),
                "priority": "p0",
                "evidence": [p["evidence"] for p in patterns["failure"]]
            })
        
        # åŸºæ–¼å­¸ç¿’é»çš„å»ºè­°
        if learnings:
            recommendations.append({
                "action": "document_learnings",
                "reason": f"ç™¼ç¾ {len(learnings)} å€‹æœ‰åƒ¹å€¼çš„å­¸ç¿’é»",
                "owner": "knowledge-team",
                "deadline": (datetime.utcnow() + timedelta(days=7)).isoformat(),
                "priority": "p1",
                "evidence": [l["evidence"] for l in learnings[:3]]
            })
        
        return recommendations
    
    def _calculate_evidence_coverage(self, analysis: Dict, patterns: Dict, learnings: List[Dict]) -> float:
        """è¨ˆç®—è­‰æ“šè¦†è“‹ç‡"""
        total_statements = 1
        statements_with_evidence = 1
        
        # æª¢æŸ¥æ¨ç†æ­¥é©Ÿ
        for step in analysis.get("reasoning_steps", []):
            total_statements += 1
            if "confidence" in step:
                statements_with_evidence += 1
        
        # æª¢æŸ¥æ¨¡å¼
        for pattern in patterns["success"] + patterns["failure"]:
            total_statements += 1
            if "evidence" in pattern:
                statements_with_evidence += 1
        
        # æª¢æŸ¥å­¸ç¿’é»
        for learning in learnings:
            total_statements += 1
            if "evidence" in learning:
                statements_with_evidence += 1
        
        return statements_with_evidence / total_statements if total_statements > 0 else 0.0
    
    def _calculate_reasoning_quality(self, analysis: Dict) -> float:
        """è¨ˆç®—æ¨ç†è³ªé‡"""
        if not analysis.get("reasoning_steps"):
            return 0.0
        
        confidences = [step.get("confidence", 0.0) for step in analysis["reasoning_steps"]]
        return sum(confidences) / len(confidences) if confidences else 0.0
    
    def _find_significant_changes(self, base: AnalysisResult, target: AnalysisResult) -> List[Dict]:
        """æŸ¥æ‰¾é¡¯è‘—è®ŠåŒ–"""
        changes = []
        
        # æ¯”è¼ƒè­‰æ“šè¦†è“‹ç‡
        coverage_diff = abs(target.evidence_coverage - base.evidence_coverage)
        if coverage_diff > self.config["delta"]["significance_threshold"]:
            changes.append({
                "changeType": "metric",
                "description": f"è­‰æ“šè¦†è“‹ç‡è®ŠåŒ–: {base.evidence_coverage:.2%} â†’ {target.evidence_coverage:.2%}",
                "impact": "non-breaking",
                "severity": "medium" if coverage_diff < 0.2 else "high",
                "beforeState": base.evidence_coverage,
                "afterState": target.evidence_coverage,
                "significanceScore": coverage_diff,
                "evidence": f"delta:{base.execution_id}_{target.execution_id}"
            })
        
        # æ¯”è¼ƒæ¨ç†è³ªé‡
        quality_diff = abs(target.reasoning_quality - base.reasoning_quality)
        if quality_diff > self.config["delta"]["significance_threshold"]:
            changes.append({
                "changeType": "metric",
                "description": f"æ¨ç†è³ªé‡è®ŠåŒ–: {base.reasoning_quality:.2%} â†’ {target.reasoning_quality:.2%}",
                "impact": "non-breaking",
                "severity": "medium" if quality_diff < 0.2 else "high",
                "beforeState": base.reasoning_quality,
                "afterState": target.reasoning_quality,
                "significanceScore": quality_diff,
                "evidence": f"delta:{base.execution_id}_{target.execution_id}"
            })
        
        return changes
    
    def _identify_improvements(self, base: AnalysisResult, target: AnalysisResult) -> List[Dict]:
        """è­˜åˆ¥æ”¹é€²"""
        improvements = []
        
        if target.evidence_coverage > base.evidence_coverage:
            improvements.append({
                "area": "evidence_coverage",
                "before": base.evidence_coverage,
                "after": target.evidence_coverage,
                "improvement": ((target.evidence_coverage - base.evidence_coverage) / base.evidence_coverage * 100),
                "evidence": f"delta:{base.execution_id}_{target.execution_id}"
            })
        
        if target.reasoning_quality > base.reasoning_quality:
            improvements.append({
                "area": "reasoning_quality",
                "before": base.reasoning_quality,
                "after": target.reasoning_quality,
                "improvement": ((target.reasoning_quality - base.reasoning_quality) / base.reasoning_quality * 100),
                "evidence": f"delta:{base.execution_id}_{target.execution_id}"
            })
        
        return improvements
    
    def _identify_regressions(self, base: AnalysisResult, target: AnalysisResult) -> List[Dict]:
        """è­˜åˆ¥å›æ­¸"""
        regressions = []
        
        if target.evidence_coverage < base.evidence_coverage * 0.95:
            regressions.append({
                "area": "evidence_coverage",
                "before": base.evidence_coverage,
                "after": target.evidence_coverage,
                "regression": ((base.evidence_coverage - target.evidence_coverage) / base.evidence_coverage * 100),
                "severity": "high",
                "evidence": f"delta:{base.execution_id}_{target.execution_id}"
            })
        
        if target.reasoning_quality < base.reasoning_quality * 0.95:
            regressions.append({
                "area": "reasoning_quality",
                "before": base.reasoning_quality,
                "after": target.reasoning_quality,
                "regression": ((base.reasoning_quality - target.reasoning_quality) / base.reasoning_quality * 100),
                "severity": "high",
                "evidence": f"delta:{base.execution_id}_{target.execution_id}"
            })
        
        return regressions
    
    def _calculate_evolution_metrics(self, base: AnalysisResult, target: AnalysisResult, changes: List[Dict]) -> Dict[str, float]:
        """è¨ˆç®—æ¼”åŒ–æŒ‡æ¨™"""
        return {
            "process_maturity_delta": 0.1,
            "automation_level_delta": 0.05,
            "self_healing_capability_delta": 0.08
        }
    
    def _identify_upgrade_triggers(self, analysis: AnalysisResult, improvements: List[Dict], regressions: List[Dict]) -> List[Dict]:
        """è­˜åˆ¥å‡ç´šè§¸ç™¼å™¨"""
        triggers = []
        
        # å¤±æ•—æ¨¡å¼è§¸ç™¼å™¨
        if analysis.failure_patterns:
            triggers.append({
                "trigger": "ANALYSIS_FAILURE_PATTERN",
                "condition": f"analysis.failurePatterns = {len(analysis.failure_patterns)}",
                "severity": "high",
                "autoUpgrade": False,
                "evidence": f"analysis:{analysis.execution_id}"
            })
        
        # å›æ­¸è§¸ç™¼å™¨
        if regressions:
            triggers.append({
                "trigger": "DELTA_REGRESSION",
                "condition": f"delta.regressions = {len(regressions)}",
                "severity": "critical",
                "autoUpgrade": True,
                "evidence": f"analysis:{analysis.execution_id}"
            })
        
        # é¡¯è‘—æ”¹é€²è§¸ç™¼å™¨
        significant_improvements = [imp for imp in improvements if imp.get("improvement", 0) > 0.1]
        if significant_improvements:
            triggers.append({
                "trigger": "DELTA_SIGNIFICANT_IMPROVEMENT",
                "condition": f"delta.improvements.score > 0.8",
                "severity": "medium",
                "autoUpgrade": False,
                "evidence": f"analysis:{analysis.execution_id}"
            })
        
        # é—œéµæ©Ÿæœƒè§¸ç™¼å™¨
        critical_recommendations = [rec for rec in analysis.recommendations if rec.get("priority") == "p0"]
        if critical_recommendations:
            triggers.append({
                "trigger": "ANALYSIS_CRITICAL_OPPORTUNITY",
                "condition": f"analysis.recommendations.priority == p0",
                "severity": "high",
                "autoUpgrade": False,
                "evidence": f"analysis:{analysis.execution_id}"
            })
        
        return triggers
    
    def _plan_failure_based_upgrade(self, context: Dict) -> List[Dict]:
        """åŸºæ–¼å¤±æ•—çš„å‡ç´šè¨ˆç•«"""
        return [
            {
                "type": "rule_upgrade",
                "operation": "add",
                "rule": "gl.validation.failure-detection-v2",
                "trigger": "failure_pattern_detected",
                "impact": "medium",
                "description": "å¢å¼·å¤±æ•—æª¢æ¸¬è¦å‰‡"
            }
        ]
    
    def _plan_regression_fix_upgrade(self, context: Dict) -> List[Dict]:
        """ä¿®å¾©å›æ­¸çš„å‡ç´šè¨ˆç•«"""
        return [
            {
                "type": "pipeline_upgrade",
                "operation": "phase_modify",
                "phase": "validation",
                "change": "increase_validation_depth",
                "rollback": "required",
                "description": "å¢åŠ é©—è­‰æ·±åº¦"
            }
        ]
    
    def _plan_optimization_upgrade(self, context: Dict) -> List[Dict]:
        """å„ªåŒ–å‡ç´šè¨ˆç•«"""
        return [
            {
                "type": "governance_upgrade",
                "operation": "policy_add",
                "policy": "gl.optimization.best-practices-v1",
                "impact": "low",
                "description": "æ·»åŠ æœ€ä½³å¯¦è¸æ”¿ç­–"
            }
        ]
    
    def _plan_general_upgrade(self, context: Dict) -> List[Dict]:
        """é€šç”¨å‡ç´šè¨ˆç•«"""
        return []
    
    def _assess_expected_impact(self, planned_changes: List[Dict], context: Dict) -> Dict[str, Any]:
        """è©•ä¼°é æœŸå½±éŸ¿"""
        return {
            "process_improvement": "medium",
            "risk_level": "low",
            "expected_benefit": "improved_validation",
            "confidence": 0.75
        }
    
    def _assess_upgrade_risks(self, planned_changes: List[Dict], expected_impact: Dict) -> Dict[str, Any]:
        """è©•ä¼°å‡ç´šé¢¨éšª"""
        return {
            "risk_level": "low",
            "potential_issues": [],
            "mitigation_strategies": ["gradual_rollout", "monitoring"],
            "rollback_available": True
        }
    
    def _execute_single_upgrade(self, change: Dict) -> Dict:
        """åŸ·è¡Œå–®å€‹å‡ç´š"""
        return {
            "status": "executed",
            "change": change,
            "timestamp": datetime.utcnow().isoformat(),
            "success": True
        }
    
    def _verify_upgrade(self, upgrade_results: List[Dict], plan: UpgradePlan) -> Dict:
        """é©—è­‰å‡ç´š"""
        success_count = sum(1 for r in upgrade_results if r.get("success", False))
        overall_success = success_count == len(upgrade_results)
        
        return {
            "overall_success": overall_success,
            "details": upgrade_results,
            "success_rate": success_count / len(upgrade_results) if upgrade_results else 0.0
        }
    
    def _extract_evolutionary_learnings(self, upgrade_results: List[Dict], plan: UpgradePlan) -> List[Dict]:
        """æå–æ¼”åŒ–å­¸ç¿’"""
        learnings = []
        
        for result in upgrade_results:
            if result.get("success"):
                learnings.append({
                    "type": "successful_upgrade",
                    "pattern": plan.trigger_reason,
                    "applicability": "similar_triggers",
                    "reuse_guidelines": "replicate_for_similar_upgrades",
                    "confidence": 0.80,
                    "evidence": f"upgrade:{plan.upgrade_id}"
                })
        
        return learnings
    
    def _update_knowledge_base(self, upgrade_log: UpgradeResult):
        """æ›´æ–°çŸ¥è­˜åº«"""
        # å°‡å‡ç´šç¶“é©—ä¿å­˜åˆ°çŸ¥è­˜åº«
        pass
    
    def _should_trigger_upgrade(self, analysis: AnalysisResult, delta_result: Optional[DeltaResult]) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²è§¸ç™¼å‡ç´š"""
        if not analysis:
            return False
        
        # æª¢æŸ¥å¤±æ•—æ¨¡å¼
        if len(analysis.failure_patterns) > 0:
            return True
        
        # æª¢æŸ¥é¡¯è‘—å›æ­¸
        if delta_result and len(delta_result.regressions) > 0:
            return True
        
        # æª¢æŸ¥å„ªåŒ–æ©Ÿæœƒ
        if len(analysis.recommendations) > 0:
            for rec in analysis.recommendations:
                if rec.get("priority") == "p0":
                    return True
        
        return False
    
    def _determine_upgrade_reason(self, analysis: AnalysisResult, delta_result: Optional[DeltaResult]) -> str:
        """ç¢ºå®šå‡ç´šåŸå› """
        reasons = []
        
        if analysis.failure_patterns:
            reasons.append("failure_pattern_detected")
        
        if delta_result and delta_result.regressions:
            reasons.append("regression_detected")
        
        if analysis.recommendations:
            for rec in analysis.recommendations:
                if rec.get("priority") == "p0":
                    reasons.append("critical_optimization_opportunity")
                    break
        
        return "|".join(reasons) if reasons else "periodic_maintenance"
    
    def _generate_evolution_cycle_report(self, execution_id: str, analysis: AnalysisResult, delta: Optional[DeltaResult], upgrade: Optional[UpgradeResult]) -> Dict:
        """ç”Ÿæˆæ¼”åŒ–é€±æœŸå ±å‘Š"""
        return {
            "cycle_completed": True,
            "timestamp": datetime.utcnow().isoformat(),
            "execution_id": execution_id,
            "analysis": {
                "learnings_count": len(analysis.learnings),
                "evidence_coverage": analysis.evidence_coverage,
                "reasoning_quality": analysis.reasoning_quality
            },
            "delta": {
                "exists": delta is not None,
                "improvements": len(delta.improvements) if delta else 0,
                "regressions": len(delta.regressions) if delta else 0
            },
            "upgrade": {
                "executed": upgrade is not None,
                "success": upgrade.success if upgrade else None,
                "learnings": len(upgrade.evolutionary_learnings) if upgrade else 0
            },
            "evolution_metrics": {
                "execution_count": len(self.execution_logs),
                "analysis_count": len(self.analysis_reports),
                "upgrade_count": len(self.upgrade_results)
            }
        }
    
    def _calculate_hash(self, data: Any) -> str:
        """è¨ˆç®—æ•¸æ“šçš„å“ˆå¸Œå€¼"""
        data_str = json.dumps(data, sort_keys=True, default=str)
        return hashlib.sha256(data_str.encode()).hexdigest()
    
    def get_evolution_statistics(self) -> Dict:
        """ç²å–æ¼”åŒ–çµ±è¨ˆ"""
        return {
            "total_executions": len(self.execution_logs),
            "total_analyses": len(self.analysis_reports),
            "total_deltas": len(self.delta_reports),
            "total_upgrades": len(self.upgrade_results),
            "success_rate": sum(1 for r in self.upgrade_results if r.success) / len(self.upgrade_results) if self.upgrade_results else 0.0,
            "average_evidence_coverage": sum(r.evidence_coverage for r in self.analysis_reports) / len(self.analysis_reports) if self.analysis_reports else 0.0,
            "average_reasoning_quality": sum(r.reasoning_quality for r in self.analysis_reports) / len(self.analysis_reports) if self.analysis_reports else 0.0
        }
    
    def save_snapshot(self):
        """ä¿å­˜ç‹€æ…‹å¿«ç…§"""
        snapshot = {
            "timestamp": datetime.utcnow().isoformat(),
            "statistics": self.get_evolution_statistics(),
            "evolution_phase": "operational"
        }
        
        snapshot_path = self.base_dir / "snapshots" / f"evolution_snapshot_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.yaml"
        with open(snapshot_path, 'w', encoding='utf-8') as f:
            yaml.dump(snapshot, f, allow_unicode=True, default_flow_style=False)
        
        print(f"ğŸ’¾ ç‹€æ…‹å¿«ç…§å·²ä¿å­˜: {snapshot_path}")
        return snapshot_path


def main():
    """ä¸»å‡½æ•¸ - æ¼”ç¤ºä½¿ç”¨"""
    print("\n" + "="*70)
    print("GL æµç¨‹è‡ªæˆ‘æ¼”åŒ–å¼•æ“ - æ¼”ç¤º")
    print("="*70 + "\n")
    
    # åˆå§‹åŒ–æ¼”åŒ–å¼•æ“
    engine = GLEvolutionEngine()
    
    # æ¨¡æ“¬ç¬¬ä¸€æ¬¡åŸ·è¡Œ
    print("ğŸ”· æ¨¡æ“¬ç¬¬ä¸€æ¬¡åŸ·è¡Œ")
    sample_execution_1 = {
        "type": "fact-pipeline",
        "status": "success",
        "input": {
            "query": "åˆ†æGLç”Ÿæ…‹ç³»çµ±ç‹€æ…‹",
            "context": "æ¯æœˆä¾‹è¡Œæª¢æŸ¥"
        },
        "output": {
            "contracts_validated": 45,
            "issues_found": 3,
            "recommendations": 12
        },
        "metadata": {
            "environment": "production",
            "version": "1.2.0",
            "user": "governance-bot",
            "contracts": ["gl-naming-ontology", "gl-platforms"],
            "rules": ["naming-validation", "structure-validation"]
        }
    }
    
    cycle_report_1 = engine.run_evolution_cycle(sample_execution_1)
    
    # æ¨¡æ“¬ç¬¬äºŒæ¬¡åŸ·è¡Œï¼ˆæœ‰æ”¹é€²ï¼‰
    print("\nğŸ”· æ¨¡æ“¬ç¬¬äºŒæ¬¡åŸ·è¡Œï¼ˆæœ‰æ”¹é€²ï¼‰")
    sample_execution_2 = {
        "type": "fact-pipeline",
        "status": "success",
        "input": {
            "query": "åˆ†æGLç”Ÿæ…‹ç³»çµ±ç‹€æ…‹",
            "context": "æ¯æœˆä¾‹è¡Œæª¢æŸ¥"
        },
        "output": {
            "contracts_validated": 48,
            "issues_found": 2,
            "recommendations": 8
        },
        "metadata": {
            "environment": "production",
            "version": "1.2.0",
            "user": "governance-bot",
            "contracts": ["gl-naming-ontology", "gl-platforms", "gl-validation-rules"],
            "rules": ["naming-validation", "structure-validation", "evidence-coverage"]
        }
    }
    
    cycle_report_2 = engine.run_evolution_cycle(sample_execution_2)
    
    # æ¨¡æ“¬ç¬¬ä¸‰æ¬¡åŸ·è¡Œï¼ˆæœ‰å¤±æ•—ï¼‰
    print("\nğŸ”· æ¨¡æ“¬ç¬¬ä¸‰æ¬¡åŸ·è¡Œï¼ˆæœ‰å¤±æ•—ï¼‰")
    sample_execution_3 = {
        "type": "fact-pipeline",
        "status": "failure",
        "input": {
            "query": "åˆ†æGLç”Ÿæ…‹ç³»çµ±ç‹€æ…‹",
            "context": "æ¯æœˆä¾‹è¡Œæª¢æŸ¥"
        },
        "output": {
            "error": "Contract validation failed",
            "failed_contract": "gl-new-contract"
        },
        "metadata": {
            "environment": "production",
            "version": "1.2.0",
            "user": "governance-bot",
            "contracts": ["gl-naming-ontology", "gl-platforms", "gl-new-contract"],
            "rules": ["naming-validation"]
        }
    }
    
    cycle_report_3 = engine.run_evolution_cycle(sample_execution_3)
    
    # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
    print("\n" + "="*70)
    print("ğŸ“ˆ æ¼”åŒ–çµ±è¨ˆ")
    print("="*70)
    stats = engine.get_evolution_statistics()
    for key, value in stats.items():
        if isinstance(value, float):
            print(f"   {key}: {value:.2%}")
        else:
            print(f"   {key}: {value}")
    
    # ä¿å­˜å¿«ç…§
    print("\n" + "="*70)
    snapshot_path = engine.save_snapshot()
    print("="*70 + "\n")
    
    print("âœ… æ¼”åŒ–å¼•æ“æ¼”ç¤ºå®Œæˆ!")
    print(f"   æ•¸æ“šç›®éŒ„: {engine.base_dir.absolute()}")
    print(f"   å¿«ç…§æ–‡ä»¶: {snapshot_path}")


if __name__ == "__main__":
    main()