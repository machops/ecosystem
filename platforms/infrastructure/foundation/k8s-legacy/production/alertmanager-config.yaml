# @ECO-governed
# @ECO-layer: infrastructure
# @ECO-semantic: alertmanager-config
# @ECO-audit-trail: ../../engine/governance/GL_SEMANTIC_ANCHOR.json
# 
# GL Unified Architecture Governance Framework Activated

apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    eco-base/urn: "urn:eco-base:platform:resource:infrastructure:foundation:k8s-legacy:production:alertmanager-config.yaml"
    eco-base/uri: "eco-base://platform/resource/infrastructure/foundation/k8s-legacy/production/alertmanager-config.yaml"
  name: alertmanager-config
  namespace: monitoring
  labels:
    eco-base/part-of: eco-base
    eco-base/governance: aligned
    app.kubernetes.io/name: alertmanager
    environment: production
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: '${SLACK_WEBHOOK_URL}'
      pagerduty_url: '${PAGERDUTY_URL}'

    templates:
    - '/etc/alertmanager/templates/*.tmpl'

    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h
      receiver: 'default'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
        continue: true
      - match:
          severity: warning
        receiver: 'warning-alerts'
      - match:
          service: machine-native-ops
        receiver: 'machine-native-ops-alerts'

    receivers:
    - name: 'default'
      slack_configs:
      - channel: '#alerts'
        send_resolved: true
        title: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        text: >-
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          *Details:*
          {{ range .Labels.SortedPairs }} • *{{ .Name }}:* {{ .Value }}
          {{ end }}
          {{ end }}

    - name: 'critical-alerts'
      slack_configs:
      - channel: '#critical-alerts'
        send_resolved: true
        title: '[CRITICAL] {{ .GroupLabels.alertname }}'
        text: >-
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          *Details:*
          {{ range .Labels.SortedPairs }} • *{{ .Name }}:* {{ .Value }}
          {{ end }}
          {{ end }}
      pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        description: '{{ .GroupLabels.alertname }}'

    - name: 'warning-alerts'
      slack_configs:
      - channel: '#alerts'
        send_resolved: true
        title: '[WARNING] {{ .GroupLabels.alertname }}'
        text: >-
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          {{ end }}

    - name: 'machine-native-ops-alerts'
      slack_configs:
      - channel: '#machine-native-ops'
        send_resolved: true
        title: '[Machine Native Ops] {{ .GroupLabels.alertname }}'
        text: >-
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          *Service:* {{ .Labels.service }}
          *Instance:* {{ .Labels.instance }}
          {{ end }}
      email_configs:
      - to: 'ops@machinenativeops.com'
        headers:
          Subject: '[Machine Native Ops Alert] {{ .GroupLabels.alertname }}'
        html: >-
          {{ range .Alerts }}
          <h3>{{ .Labels.alertname }}</h3>
          <p><strong>Severity:</strong> {{ .Labels.severity }}</p>
          <p><strong>Description:</strong> {{ .Annotations.description }}</p>
          <p><strong>Service:</strong> {{ .Labels.service }}</p>
          <p><strong>Instance:</strong> {{ .Labels.instance }}</p>
          {{ end }}

    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'cluster', 'service']