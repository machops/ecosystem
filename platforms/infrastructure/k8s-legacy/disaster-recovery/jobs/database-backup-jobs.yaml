--- null
---
apiVersion: batch/v1
kind: CronJob
metadata:
  annotations:
    eco-base/uri: eco-base://k8s/core/cronjob/postgres-backup
    eco-base/urn: urn:eco-base:k8s:core:cronjob:postgres-backup:sha256-1c0bd21122bfe978af34c10478c2c0856abb4a566dfc936de33e1eadbabd4444
  labels:
    app.kubernetes.io/component: backup
    app.kubernetes.io/name: postgres-backup
    eco-base/governance: aligned
    eco-base/part-of: eco-base
  name: postgres-backup
  namespace: platform-03
spec:
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 3
      template:
        spec:
          containers:
          - command:
            - /bin/sh
            - -c
            - "set -e\necho \"Starting PostgreSQL backup at $(date)\"\n\n# Create\
              \ backup filename with timestamp\nBACKUP_FILE=\"/backup/postgres_$(date\
              \ +%Y%m%d_%H%M%S).sql.gz\"\n\n# Perform backup\npg_dump -h postgres.machine-native-ops.svc\
              \ \\\n        -U postgres \\\n        -d machine_native_ops \\\n   \
              \     --format=plain \\\n        --no-owner \\\n        --no-acl \\\n\
              \        --compress=9 \\\n        > \"${BACKUP_FILE}\"\n\n# Upload to\
              \ S3\naws s3 cp \"${BACKUP_FILE}\" \\\n         s3://machine-native-ops-backups/postgres/\
              \ \\\n         --storage-class STANDARD_IA \\\n         --metadata \"\
              timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)\"\n\n# Clean up old backups\
              \ (keep 7 days)\nfind /backup -name \"postgres_*.sql.gz\" -mtime +7\
              \ -delete\n\n# Cleanup S3 old backups (keep 30 days)\naws s3 ls s3://machine-native-ops-backups/postgres/\
              \ | \\\n  while read -r line; do\n    fileName=$(echo \"$line\" | awk\
              \ '{print $4}')\n    fileDate=$(echo \"$line\" | awk '{print $1\" \"\
              $2}')\n    fileTimestamp=$(date -d \"$fileDate\" +%s)\n    currentTimestamp=$(date\
              \ +%s)\n    age=$(( (currentTimestamp - fileTimestamp) / 86400 ))\n\
              \    if [ $age -gt 30 ]; then\n      aws s3 rm \"s3://machine-native-ops-backups/postgres/$fileName\"\
              \n    fi\n  done\n\necho \"PostgreSQL backup completed successfully\
              \ at $(date)\"\necho \"Backup file: ${BACKUP_FILE}\"\n"
            env:
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  key: password
                  name: postgres-secret
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  key: access-key-id
                  name: aws-credentials
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  key: secret-access-key
                  name: aws-credentials
            - name: AWS_DEFAULT_REGION
              value: us-east-1
            image: postgres:15-alpine
            name: postgres-backup
            resources:
              limits:
                cpu: 500m
                memory: 512Mi
              requests:
                cpu: 200m
                memory: 256Mi
            volumeMounts:
            - mountPath: /backup
              name: backup
            - mountPath: /var/log/backup
              name: backup-logs
          restartPolicy: OnFailure
          serviceAccountName: backup-service-account
          volumes:
          - name: backup
            persistentVolumeClaim:
              claimName: postgres-backup-pvc
          - name: backup-logs
            persistentVolumeClaim:
              claimName: backup-logs-pvc
  schedule: 0 * * * *
  successfulJobsHistoryLimit: 3
---
apiVersion: batch/v1
kind: CronJob
metadata:
  annotations:
    eco-base/uri: eco-base://k8s/core/cronjob/redis-backup
    eco-base/urn: urn:eco-base:k8s:core:cronjob:redis-backup:sha256-63664324514d678f897ce46e17a90272ce1e31fb6f29f3beb23f6a17f1c88a5a
  labels:
    app.kubernetes.io/component: backup
    app.kubernetes.io/name: redis-backup
    eco-base/governance: aligned
    eco-base/part-of: eco-base
  name: redis-backup
  namespace: platform-03
spec:
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 5
  jobTemplate:
    spec:
      backoffLimit: 3
      template:
        spec:
          containers:
          - command:
            - /bin/sh
            - -c
            - "set -e\necho \"Starting Redis backup at $(date)\"\n\n# Trigger background\
              \ save\nredis-cli -h redis.machine-native-ops.svc BGSAVE\n\n# Wait for\
              \ BGSAVE to complete\necho \"Waiting for BGSAVE to complete...\"\nwhile\
              \ true; do\n  LASTSAVE=$(redis-cli -h redis.machine-native-ops.svc LASTSAVE)\n\
              \  echo \"Last save timestamp: $LASTSAVE\"\n  sleep 5\ndone &\n\n# Copy\
              \ RDB file\nBACKUP_FILE=\"/backup/redis_$(date +%Y%m%d_%H%M%S).rdb\"\
              \nkubectl exec -n machine-native-ops redis-0 -- cat /data/dump.rdb >\
              \ \"${BACKUP_FILE}\"\n\n# Compress backup\ngzip \"${BACKUP_FILE}\"\n\
              BACKUP_FILE=\"${BACKUP_FILE}.gz\"\n\n# Upload to S3\naws s3 cp \"${BACKUP_FILE}\"\
              \ \\\n         s3://machine-native-ops-backups/redis/ \\\n         --storage-class\
              \ STANDARD_IA \\\n         --metadata \"timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)\"\
              \n\n# Clean up old backups (keep 7 days)\nfind /backup -name \"redis_*.rdb.gz\"\
              \ -mtime +7 -delete\n\n# Cleanup S3 old backups (keep 7 days)\naws s3\
              \ ls s3://machine-native-ops-backups/redis/ | \\\n  while read -r line;\
              \ do\n    fileName=$(echo \"$line\" | awk '{print $4}')\n    fileDate=$(echo\
              \ \"$line\" | awk '{print $1\" \"$2}')\n    fileTimestamp=$(date -d\
              \ \"$fileDate\" +%s)\n    currentTimestamp=$(date +%s)\n    age=$((\
              \ (currentTimestamp - fileTimestamp) / 86400 ))\n    if [ $age -gt 7\
              \ ]; then\n      aws s3 rm \"s3://machine-native-ops-backups/redis/$fileName\"\
              \n    fi\n  done\n\necho \"Redis backup completed successfully at $(date)\"\
              \necho \"Backup file: ${BACKUP_FILE}\"\n"
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  key: access-key-id
                  name: aws-credentials
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  key: secret-access-key
                  name: aws-credentials
            - name: AWS_DEFAULT_REGION
              value: us-east-1
            image: redis:7-alpine
            name: redis-backup
            resources:
              limits:
                cpu: 200m
                memory: 256Mi
              requests:
                cpu: 100m
                memory: 128Mi
            volumeMounts:
            - mountPath: /backup
              name: backup
            - mountPath: /var/log/backup
              name: backup-logs
          restartPolicy: OnFailure
          serviceAccountName: backup-service-account
          volumes:
          - name: backup
            persistentVolumeClaim:
              claimName: redis-backup-pvc
          - name: backup-logs
            persistentVolumeClaim:
              claimName: backup-logs-pvc
  schedule: '*/30 * * * *'
  successfulJobsHistoryLimit: 5
---
apiVersion: batch/v1
kind: CronJob
metadata:
  annotations:
    eco-base/uri: eco-base://k8s/core/cronjob/config-backup
    eco-base/urn: urn:eco-base:k8s:core:cronjob:config-backup:sha256-68c3f6d9df5812a5e95961ace883a51db863bb9d4118bd1dc092f451b3bb75eb
  labels:
    app.kubernetes.io/component: backup
    app.kubernetes.io/name: config-backup
    eco-base/governance: aligned
    eco-base/part-of: eco-base
  name: config-backup
  namespace: platform-03
spec:
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 10
  jobTemplate:
    spec:
      backoffLimit: 3
      template:
        spec:
          containers:
          - command:
            - /bin/sh
            - -c
            - "set -e\necho \"Starting configuration backup at $(date)\"\n\n# Create\
              \ backup directory\nBACKUP_DIR=\"/backup/config_$(date +%Y%m%d_%H%M%S)\"\
              \nmkdir -p \"${BACKUP_DIR}\"\n\n# Export ConfigMaps\nkubectl get configmaps\
              \ -n machine-native-ops -o yaml > \"${BACKUP_DIR}/configmaps.yaml\"\n\
              \n# Export Secrets (without values)\nkubectl get secrets -n machine-native-ops\
              \ -o yaml > \"${BACKUP_DIR}/secrets-metadata.yaml\"\n\n# Export Deployments\n\
              kubectl get deployments -n machine-native-ops -o yaml > \"${BACKUP_DIR}/deployments.yaml\"\
              \n\n# Export StatefulSets\nkubectl get statefulsets -n machine-native-ops\
              \ -o yaml > \"${BACKUP_DIR}/statefulsets.yaml\"\n\n# Export Services\n\
              kubectl get services -n machine-native-ops -o yaml > \"${BACKUP_DIR}/services.yaml\"\
              \n\n# Export Ingress\nkubectl get ingress -n machine-native-ops -o yaml\
              \ > \"${BACKUP_DIR}/ingress.yaml\"\n\n# Export Custom Resources\nkubectl\
              \ get virtualservices -n machine-native-ops -o yaml > \"${BACKUP_DIR}/virtualservices.yaml\"\
              \ || true\nkubectl get destinationrules -n machine-native-ops -o yaml\
              \ > \"${BACKUP_DIR}/destinationrules.yaml\" || true\n\n# Create archive\n\
              tar -czf \"/backup/config_$(date +%Y%m%d_%H%M%S).tar.gz\" -C /backup\
              \ \"$(basename ${BACKUP_DIR})\"\nrm -rf \"${BACKUP_DIR}\"\n\n# Upload\
              \ to S3\naws s3 cp \"/backup/config_$(date +%Y%m%d_%H%M%S).tar.gz\"\
              \ \\\n         s3://machine-native-ops-backups/config/ \\\n        \
              \ --storage-class STANDARD_IA\n\n# Clean up old backups (keep 30 days)\n\
              find /backup -name \"config_*.tar.gz\" -mtime +30 -delete\n\n# Cleanup\
              \ S3 old backups (keep 90 days)\naws s3 ls s3://machine-native-ops-backups/config/\
              \ | \\\n  while read -r line; do\n    fileName=$(echo \"$line\" | awk\
              \ '{print $4}')\n    fileDate=$(echo \"$line\" | awk '{print $1\" \"\
              $2}')\n    fileTimestamp=$(date -d \"$fileDate\" +%s)\n    currentTimestamp=$(date\
              \ +%s)\n    age=$(( (currentTimestamp - fileTimestamp) / 86400 ))\n\
              \    if [ $age -gt 90 ]; then\n      aws s3 rm \"s3://machine-native-ops-backups/config/$fileName\"\
              \n    fi\n  done\n\necho \"Configuration backup completed successfully\
              \ at $(date)\"\n"
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  key: access-key-id
                  name: aws-credentials
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  key: secret-access-key
                  name: aws-credentials
            - name: AWS_DEFAULT_REGION
              value: us-east-1
            image: bitnami/kubectl:latest
            name: config-backup
            resources:
              limits:
                cpu: 200m
                memory: 256Mi
              requests:
                cpu: 100m
                memory: 128Mi
            volumeMounts:
            - mountPath: /backup
              name: backup
            - mountPath: /var/log/backup
              name: backup-logs
          restartPolicy: OnFailure
          serviceAccountName: backup-service-account
          volumes:
          - name: backup
            persistentVolumeClaim:
              claimName: config-backup-pvc
          - name: backup-logs
            persistentVolumeClaim:
              claimName: backup-logs-pvc
  schedule: '*/30 * * * *'
  successfulJobsHistoryLimit: 10
---
apiVersion: batch/v1
kind: CronJob
metadata:
  annotations:
    eco-base/uri: eco-base://k8s/core/cronjob/backup-validation
    eco-base/urn: urn:eco-base:k8s:core:cronjob:backup-validation:sha256-d24c47933f76922a39b8f28b20136366a33d22aa0e64eb335969e894568e30e0
  labels:
    app.kubernetes.io/component: backup
    app.kubernetes.io/name: backup-validation
    eco-base/governance: aligned
    eco-base/part-of: eco-base
  name: backup-validation
  namespace: platform-03
spec:
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 7
  jobTemplate:
    spec:
      backoffLimit: 1
      template:
        spec:
          containers:
          - command:
            - /bin/sh
            - -c
            - "set -e\necho \"Starting backup validation at $(date)\"\n\n# Validate\
              \ Velero backups\necho \"Checking Velero backups...\"\nLATEST_BACKUP=$(velero\
              \ backup get -o json | jq -r '.items | sort_by(.metadata.creationTimestamp)\
              \ | reverse | .[0].metadata.name')\nBACKUP_STATUS=$(velero backup get\
              \ $LATEST_BACKUP -o json | jq -r '.status.phase')\n\nif [ \"$BACKUP_STATUS\"\
              \ != \"Completed\" ]; then\n  echo \"ERROR: Velero backup $LATEST_BACKUP\
              \ failed with status: $BACKUP_STATUS\"\n  exit 1\nfi\n\necho \"✓ Velero\
              \ backup validation passed: $LATEST_BACKUP\"\n\n# Validate PostgreSQL\
              \ backups in S3\necho \"Checking PostgreSQL backups...\"\nPG_BACKUP_COUNT=$(aws\
              \ s3 ls s3://machine-native-ops-backups/postgres/ | wc -l)\nif [ \"\
              $PG_BACKUP_COUNT\" -lt 24 ]; then  # At least 24 hourly backups\n  echo\
              \ \"ERROR: Insufficient PostgreSQL backups: $PG_BACKUP_COUNT (expected\
              \ >= 24)\"\n  exit 1\nfi\necho \"✓ PostgreSQL backup validation passed:\
              \ $PG_BACKUP_COUNT backups\"\n\n# Validate Redis backups in S3\necho\
              \ \"Checking Redis backups...\"\nREDIS_BACKUP_COUNT=$(aws s3 ls s3://machine-native-ops-backups/redis/\
              \ | wc -l)\nif [ \"$REDIS_BACKUP_COUNT\" -lt 48 ]; then  # At least\
              \ 48 backups (every 30 min)\n  echo \"ERROR: Insufficient Redis backups:\
              \ $REDIS_BACKUP_COUNT (expected >= 48)\"\n  exit 1\nfi\necho \"✓ Redis\
              \ backup validation passed: $REDIS_BACKUP_COUNT backups\"\n\n# Validate\
              \ configuration backups\necho \"Checking configuration backups...\"\n\
              CONFIG_BACKUP_COUNT=$(aws s3 ls s3://machine-native-ops-backups/config/\
              \ | wc -l)\nif [ \"$CONFIG_BACKUP_COUNT\" -lt 48 ]; then  # At least\
              \ 48 backups\n  echo \"ERROR: Insufficient configuration backups: $CONFIG_BACKUP_COUNT\
              \ (expected >= 48)\"\n  exit 1\nfi\necho \"✓ Configuration backup validation\
              \ passed: $CONFIG_BACKUP_COUNT backups\"\n\necho \"All backup validations\
              \ passed successfully at $(date)\"\n"
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  key: access-key-id
                  name: aws-credentials
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  key: secret-access-key
                  name: aws-credentials
            - name: AWS_DEFAULT_REGION
              value: us-east-1
            image: bitnami/kubectl:latest
            name: backup-validator
            resources:
              limits:
                cpu: 200m
                memory: 256Mi
              requests:
                cpu: 100m
                memory: 128Mi
            volumeMounts:
            - mountPath: /var/log/backup
              name: backup-logs
          restartPolicy: OnFailure
          serviceAccountName: backup-service-account
          volumes:
          - name: backup-logs
            persistentVolumeClaim:
              claimName: backup-logs-pvc
  schedule: 0 3 * * *
  successfulJobsHistoryLimit: 7
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    eco-base/uri: eco-base://platform/resource/infrastructure/k8s-legacy/disaster-recovery/jobs/database-backup-jobs.yaml
    eco-base/urn: urn:eco-base:platform:resource:infrastructure:k8s-legacy:disaster-recovery:jobs:database-backup-jobs.yaml
  name: backup-service-account
  namespace: platform-03
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations:
    eco-base/uri: eco-base://platform/resource/infrastructure/k8s-legacy/disaster-recovery/jobs/database-backup-jobs.yaml
    eco-base/urn: urn:eco-base:platform:resource:infrastructure:k8s-legacy:disaster-recovery:jobs:database-backup-jobs.yaml
  name: backup-role
  namespace: platform-03
rules:
- apiGroups:
  - ''
  resources:
  - pods
  - pods/exec
  verbs:
  - get
  - list
  - create
- apiGroups:
  - ''
  resources:
  - persistentvolumes
  - persistentvolumeclaims
  verbs:
  - get
  - list
- apiGroups:
  - ''
  resources:
  - configmaps
  - secrets
  verbs:
  - get
  - list
- apiGroups:
  - apps
  resources:
  - deployments
  - statefulsets
  - daemonsets
  verbs:
  - get
  - list
- apiGroups:
  - networking.istio.io
  resources:
  - virtualservices
  - destinationrules
  verbs:
  - get
  - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  annotations:
    eco-base/uri: eco-base://platform/resource/infrastructure/k8s-legacy/disaster-recovery/jobs/database-backup-jobs.yaml
    eco-base/urn: urn:eco-base:platform:resource:infrastructure:k8s-legacy:disaster-recovery:jobs:database-backup-jobs.yaml
  name: backup-role-binding
  namespace: platform-03
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: backup-role
subjects:
- kind: ServiceAccount
  name: backup-service-account
  namespace: platform-03
